{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "N2MRk5Cq1By6",
        "outputId": "d57a1e5d-7fec-43fc-f60e-5e52408d004a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nComplete training pipeline following the competition's standard approach:\\n1. Load neural data from HDF5 files\\n2. Train GRU encoder (without day-specific layers for simplicity)\\n3. CTC loss for phoneme prediction\\n4. Language model integration (N-gram + OPT-6.7B)\\n5. Word Error Rate (WER) evaluation\\n\\nBased on the official competition baseline but simplified for easier replication.\\nDesigned to run in Google Colab with minimal setup.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Brain-to-Text 2025: Standard Training Pipeline (Simplified)\n",
        "# SECTION 1: HEADER AND DOCUMENTATION\n",
        "# ============================================================================\n",
        "\"\"\"\n",
        "Complete training pipeline following the competition's standard approach:\n",
        "1. Load neural data from HDF5 files\n",
        "2. Train GRU encoder (without day-specific layers for simplicity)\n",
        "3. CTC loss for phoneme prediction\n",
        "4. Language model integration (N-gram + OPT-6.7B)\n",
        "5. Word Error Rate (WER) evaluation\n",
        "\n",
        "Based on the official competition baseline but simplified for easier replication.\n",
        "Designed to run in Google Colab with minimal setup.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K06chDf1HUD"
      },
      "source": [
        "# SECTION 2: IMPORTS AND SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1YbvKtT1GWn",
        "outputId": "d92dba47-a693-454c-c11a-874c75ba2f6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è  ctcdecode not available. Install with: pip install https://github.com/parlance/ctcdecode/archive/master.zip\n",
            "üîß Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional, Union\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# For CTC decoding and evaluation\n",
        "try:\n",
        "    import ctcdecode\n",
        "    HAS_CTC_DECODE = True\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  ctcdecode not available. Install with: pip install https://github.com/parlance/ctcdecode/archive/master.zip\")\n",
        "    HAS_CTC_DECODE = False\n",
        "\n",
        "# For language model integration\n",
        "try:\n",
        "    from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "    import gc\n",
        "    HAS_TRANSFORMERS = True\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  transformers not available. Install with: pip install transformers accelerate\")\n",
        "    HAS_TRANSFORMERS = False\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üîß Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaBt3Y8q1QCH"
      },
      "source": [
        "# SECTION 3: CONSTANTS AND CONFIGURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0FAp3pSG1GTx"
      },
      "outputs": [],
      "source": [
        "# Phoneme mapping from competition\n",
        "PHONEME_TO_ID = {\n",
        "    'BLANK': 0,    # CTC blank symbol\n",
        "    'AA': 1, 'AE': 2, 'AH': 3, 'AO': 4, 'AW': 5,\n",
        "    'AY': 6, 'B': 7, 'CH': 8, 'D': 9, 'DH': 10,\n",
        "    'EH': 11, 'ER': 12, 'EY': 13, 'F': 14, 'G': 15,\n",
        "    'HH': 16, 'IH': 17, 'IY': 18, 'JH': 19, 'K': 20,\n",
        "    'L': 21, 'M': 22, 'N': 23, 'NG': 24, 'OW': 25,\n",
        "    'OY': 26, 'P': 27, 'R': 28, 'S': 29, 'SH': 30,\n",
        "    'T': 31, 'TH': 32, 'UH': 33, 'UW': 34, 'V': 35,\n",
        "    'W': 36, 'Y': 37, 'Z': 38, 'ZH': 39,\n",
        "    'SIL': 40,    # Silence token\n",
        "}\n",
        "\n",
        "ID_TO_PHONEME = {v: k for k, v in PHONEME_TO_ID.items()}\n",
        "N_PHONEMES = len(PHONEME_TO_ID)\n",
        "\n",
        "# Model configuration (based on competition baseline)\n",
        "class Config:\n",
        "    # Data parameters\n",
        "    neural_dim = 512          # Number of neural features\n",
        "    sample_rate = 50          # 20ms bins = 50Hz\n",
        "\n",
        "    # Model architecture\n",
        "    hidden_size = 768         # GRU hidden units\n",
        "    num_layers = 5            # Number of GRU layers\n",
        "    dropout = 0.4             # RNN dropout\n",
        "    input_dropout = 0.2       # Input dropout\n",
        "\n",
        "    # Training parameters\n",
        "    batch_size = 32          # Reduced from 64 for memory efficiency\n",
        "    learning_rate = 5e-5\n",
        "    weight_decay = 1e-3\n",
        "    num_epochs = 50\n",
        "    grad_clip = 10.0\n",
        "\n",
        "    # CTC parameters\n",
        "    blank_id = 0              # CTC blank token\n",
        "\n",
        "    # Evaluation parameters\n",
        "    beam_width = 100          # Beam search width\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Config(neural_dim={self.neural_dim}, hidden_size={self.hidden_size}, num_layers={self.num_layers})\"\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRz5MQ-Q1Wnv"
      },
      "source": [
        "# SECTION 4: DATA LOADING AND DATASET CLASSES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bEi_hC821GRU"
      },
      "outputs": [],
      "source": [
        "class Brain2TextDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for Brain-to-Text neural data\n",
        "    Simplified version without day-specific handling\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_dir: str, split: str = 'train', config: Config = config):\n",
        "        \"\"\"\n",
        "        Initialize dataset\n",
        "\n",
        "        Args:\n",
        "            data_dir: Directory containing HDF5 files\n",
        "            split: 'train', 'val', or 'test'\n",
        "            config: Model configuration\n",
        "        \"\"\"\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.split = split\n",
        "        self.config = config\n",
        "\n",
        "        # Load all data\n",
        "        self.samples = self._load_data()\n",
        "        print(f\"üìä Loaded {len(self.samples)} samples for {split} split\")\n",
        "\n",
        "    def _load_data(self) -> List[Dict]:\n",
        "        \"\"\"Load neural data from HDF5 files\"\"\"\n",
        "        samples = []\n",
        "\n",
        "        # Find HDF5 files matching the split\n",
        "        all_hdf5_files = list(self.data_dir.rglob(\"*.hdf5\"))\n",
        "        if not all_hdf5_files:\n",
        "            raise ValueError(f\"No HDF5 files found in {self.data_dir}\")\n",
        "\n",
        "        # Filter files based on split (e.g., data_train.hdf5, data_val.hdf5, data_test.hdf5)\n",
        "        split_patterns = [f\"data_{self.split}\", f\"_{self.split}.\", f\"{self.split}_data\"]\n",
        "        hdf5_files = []\n",
        "        for f in all_hdf5_files:\n",
        "            fname_lower = f.name.lower()\n",
        "            if any(pattern in fname_lower for pattern in split_patterns):\n",
        "                hdf5_files.append(f)\n",
        "\n",
        "        # If no split-specific files found, fall back to all files (with warning)\n",
        "        if not hdf5_files:\n",
        "            print(f\"‚ö†Ô∏è  No files matching split '{self.split}' found. Loading all HDF5 files.\")\n",
        "            hdf5_files = all_hdf5_files\n",
        "\n",
        "        print(f\"üìÅ Found {len(hdf5_files)} HDF5 files for '{self.split}' split\")\n",
        "\n",
        "        transcription_count = 0\n",
        "        transcription_sources = {'sentence_label': 0, 'transcription': 0, 'sentenceText': 0, 'none': 0}\n",
        "\n",
        "        for file_path in hdf5_files:\n",
        "            print(f\"Loading {file_path.name} for {self.split}...\")\n",
        "\n",
        "            with h5py.File(file_path, 'r') as f:\n",
        "                # Debug: Show structure of first trial\n",
        "                first_trial_key = list(f.keys())[0] if f.keys() else None\n",
        "                if first_trial_key:\n",
        "                    first_trial = f[first_trial_key]\n",
        "                    print(f\"   üìã First trial keys: {list(first_trial.keys())}\")\n",
        "                    print(f\"   üìã First trial attrs: {list(first_trial.attrs.keys())}\")\n",
        "\n",
        "                for trial_key in f.keys():\n",
        "                    trial_group = f[trial_key]\n",
        "\n",
        "                    # Extract data\n",
        "                    neural_features = trial_group['input_features'][:]  # (time_steps, 512)\n",
        "                    n_time_steps = trial_group.attrs['n_time_steps']\n",
        "\n",
        "                    # Skip samples without labels for training\n",
        "                    if 'seq_class_ids' not in trial_group and self.split != 'test':\n",
        "                        continue\n",
        "\n",
        "                    phoneme_ids = trial_group['seq_class_ids'][:] if 'seq_class_ids' in trial_group else None\n",
        "                    seq_len = trial_group.attrs['seq_len'] if 'seq_len' in trial_group.attrs else 0\n",
        "\n",
        "                    # Extract text labels if available - try multiple possible field names\n",
        "                    transcription = None\n",
        "                    sentence_label = None\n",
        "\n",
        "                    # Method 1: Try 'transcription' dataset\n",
        "                    if 'transcription' in trial_group:\n",
        "                        trans_data = trial_group['transcription'][:]\n",
        "                        try:\n",
        "                            if isinstance(trans_data, bytes):\n",
        "                                transcription = trans_data.decode('utf-8').rstrip('\\x00')\n",
        "                            elif isinstance(trans_data, np.ndarray):\n",
        "                                if trans_data.dtype.kind in ['S', 'U', 'O']:\n",
        "                                    transcription = str(trans_data.item()) if trans_data.ndim == 0 else ''.join([str(x) for x in trans_data])\n",
        "                                else:\n",
        "                                    transcription = ''.join([chr(c) for c in trans_data if c != 0])\n",
        "                            else:\n",
        "                                transcription = str(trans_data)\n",
        "                            transcription_sources['transcription'] += 1\n",
        "                        except Exception as e:\n",
        "                            pass\n",
        "\n",
        "                    # Method 2: Try 'sentenceText' dataset (alternative field name)\n",
        "                    if transcription is None and 'sentenceText' in trial_group:\n",
        "                        try:\n",
        "                            trans_data = trial_group['sentenceText'][:]\n",
        "                            if isinstance(trans_data, bytes):\n",
        "                                transcription = trans_data.decode('utf-8').rstrip('\\x00')\n",
        "                            elif isinstance(trans_data, np.ndarray):\n",
        "                                transcription = ''.join([chr(c) for c in trans_data if c != 0])\n",
        "                            else:\n",
        "                                transcription = str(trans_data)\n",
        "                            transcription_sources['sentenceText'] += 1\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                    # Method 3: Try 'sentence_label' in attrs (preferred for WER)\n",
        "                    if 'sentence_label' in trial_group.attrs:\n",
        "                        try:\n",
        "                            label_data = trial_group.attrs['sentence_label']\n",
        "                            if isinstance(label_data, bytes):\n",
        "                                sentence_label = label_data.decode('utf-8').rstrip('\\x00')\n",
        "                            elif isinstance(label_data, str):\n",
        "                                sentence_label = label_data\n",
        "                            else:\n",
        "                                sentence_label = str(label_data)\n",
        "                            transcription_sources['sentence_label'] += 1\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                    # Method 4: Try 'sentenceText' in attrs\n",
        "                    if sentence_label is None and 'sentenceText' in trial_group.attrs:\n",
        "                        try:\n",
        "                            label_data = trial_group.attrs['sentenceText']\n",
        "                            if isinstance(label_data, bytes):\n",
        "                                sentence_label = label_data.decode('utf-8').rstrip('\\x00')\n",
        "                            else:\n",
        "                                sentence_label = str(label_data)\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                    # Use sentence_label if available, otherwise transcription\n",
        "                    final_transcription = sentence_label or transcription\n",
        "\n",
        "                    if final_transcription:\n",
        "                        transcription_count += 1\n",
        "                    else:\n",
        "                        transcription_sources['none'] += 1\n",
        "\n",
        "                    sample = {\n",
        "                        'neural_features': torch.FloatTensor(neural_features),\n",
        "                        'n_time_steps': n_time_steps,\n",
        "                        'phoneme_ids': torch.LongTensor(phoneme_ids) if phoneme_ids is not None else None,\n",
        "                        'seq_len': seq_len,\n",
        "                        'transcription': final_transcription,\n",
        "                        'session': trial_group.attrs.get('session', 'unknown'),\n",
        "                        'trial_key': trial_key\n",
        "                    }\n",
        "\n",
        "                    samples.append(sample)\n",
        "\n",
        "        # Print transcription statistics\n",
        "        print(f\"üìù Transcription stats: {transcription_count}/{len(samples)} samples have transcriptions\")\n",
        "        print(f\"   Sources: {transcription_sources}\")\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict:\n",
        "        return self.samples[idx]\n",
        "\n",
        "def collate_fn(batch: List[Dict]) -> Dict:\n",
        "    \"\"\"\n",
        "    Collate function for DataLoader\n",
        "    Handles variable-length sequences with padding\n",
        "    \"\"\"\n",
        "    # Separate data\n",
        "    neural_features = [sample['neural_features'] for sample in batch]\n",
        "    n_time_steps = [sample['n_time_steps'] for sample in batch]\n",
        "    phoneme_ids = [sample['phoneme_ids'] for sample in batch if sample['phoneme_ids'] is not None]\n",
        "    seq_lens = [sample['seq_len'] for sample in batch]\n",
        "    transcriptions = [sample['transcription'] for sample in batch]\n",
        "\n",
        "    # Pad neural features\n",
        "    neural_features_padded = pad_sequence(neural_features, batch_first=True, padding_value=0.0)\n",
        "\n",
        "    # Pad phoneme sequences if available\n",
        "    phoneme_ids_padded = None\n",
        "    if phoneme_ids:\n",
        "        phoneme_ids_padded = pad_sequence(phoneme_ids, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {\n",
        "        'neural_features': neural_features_padded,  # (batch, max_time, 512)\n",
        "        'n_time_steps': torch.LongTensor(n_time_steps),\n",
        "        'phoneme_ids': phoneme_ids_padded,  # (batch, max_seq_len)\n",
        "        'seq_lens': torch.LongTensor(seq_lens),\n",
        "        'transcriptions': transcriptions\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlK0ACgz1gT3"
      },
      "source": [
        "# SECTION 5: MODEL ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RpELMPYH1GOc"
      },
      "outputs": [],
      "source": [
        "class SimplifiedGRUDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Simplified GRU decoder without day-specific layers\n",
        "    Based on the competition baseline but streamlined\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # Input processing\n",
        "        self.input_dropout = nn.Dropout(config.input_dropout)\n",
        "\n",
        "        # Main GRU layers\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=config.neural_dim,\n",
        "            hidden_size=config.hidden_size,\n",
        "            num_layers=config.num_layers,\n",
        "            dropout=config.dropout if config.num_layers > 1 else 0,\n",
        "            batch_first=True,\n",
        "            bidirectional=False\n",
        "        )\n",
        "\n",
        "        # Initialize GRU weights\n",
        "        for name, param in self.gru.named_parameters():\n",
        "            if 'weight_hh' in name:\n",
        "                nn.init.orthogonal_(param)\n",
        "            elif 'weight_ih' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "\n",
        "        # Output projection to phonemes\n",
        "        self.output_projection = nn.Linear(config.hidden_size, N_PHONEMES)\n",
        "        nn.init.xavier_uniform_(self.output_projection.weight)\n",
        "\n",
        "        # Learnable initial hidden state\n",
        "        self.h0 = nn.Parameter(torch.zeros(config.num_layers, 1, config.hidden_size))\n",
        "        nn.init.xavier_uniform_(self.h0)\n",
        "\n",
        "    def forward(self, neural_features: torch.Tensor, lengths: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass with packed sequences for efficiency (skips padding computation)\n",
        "\n",
        "        Args:\n",
        "            neural_features: (batch, time, 512) neural data\n",
        "            lengths: (batch,) actual sequence lengths\n",
        "\n",
        "        Returns:\n",
        "            logits: (batch, time, n_phonemes) phoneme logits\n",
        "        \"\"\"\n",
        "        batch_size = neural_features.size(0)\n",
        "        max_len = neural_features.size(1)\n",
        "\n",
        "        # Apply input dropout\n",
        "        x = self.input_dropout(neural_features)\n",
        "\n",
        "        # Initialize hidden state\n",
        "        h0 = self.h0.expand(self.config.num_layers, batch_size, self.config.hidden_size).contiguous()\n",
        "\n",
        "        # Pack sequences to skip padding computation (major speedup!)\n",
        "        # Lengths must be on CPU for pack_padded_sequence\n",
        "        lengths_cpu = lengths.cpu()\n",
        "\n",
        "        # Clamp lengths to max_len to avoid errors if lengths exceed tensor size\n",
        "        lengths_clamped = torch.clamp(lengths_cpu, max=max_len)\n",
        "\n",
        "        # Pack the padded sequence\n",
        "        packed_input = pack_padded_sequence(\n",
        "            x,\n",
        "            lengths_clamped,\n",
        "            batch_first=True,\n",
        "            enforce_sorted=False  # Allows unsorted sequences (slightly slower but more flexible)\n",
        "        )\n",
        "\n",
        "        # GRU forward pass on packed sequence (only processes real data, skips padding!)\n",
        "        packed_output, _ = self.gru(packed_input, h0)\n",
        "\n",
        "        # Unpack back to padded format for output projection\n",
        "        gru_output, _ = pad_packed_sequence(packed_output, batch_first=True, total_length=max_len)\n",
        "\n",
        "        # Project to phoneme space\n",
        "        logits = self.output_projection(gru_output)  # (batch, time, n_phonemes)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA4h6MvO8onf"
      },
      "source": [
        "# SECTION 6: TRAINING FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8LDEFOU21GLT"
      },
      "outputs": [],
      "source": [
        "class Brain2TextTrainer:\n",
        "    \"\"\"\n",
        "    Trainer class for the Brain-to-Text model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, config: Config):\n",
        "        self.model = model\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        # Move model to device\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Loss function (CTC Loss)\n",
        "        self.ctc_loss = nn.CTCLoss(blank=config.blank_id, reduction='mean', zero_infinity=True)\n",
        "\n",
        "        # Optimizer\n",
        "        self.optimizer = optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=config.learning_rate,\n",
        "            weight_decay=config.weight_decay\n",
        "        )\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=config.num_epochs)\n",
        "\n",
        "        # Training history\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train_epoch(self, train_loader: DataLoader) -> float:\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            # Move to device\n",
        "            neural_features = batch['neural_features'].to(self.device)\n",
        "            phoneme_ids = batch['phoneme_ids'].to(self.device) if batch['phoneme_ids'] is not None else None\n",
        "            lengths = batch['n_time_steps'].to(self.device)\n",
        "            seq_lens = batch['seq_lens'].to(self.device)\n",
        "\n",
        "            # Skip batch if no labels\n",
        "            if phoneme_ids is None:\n",
        "                continue\n",
        "\n",
        "            # Forward pass\n",
        "            logits = self.model(neural_features, lengths)  # (batch, time, n_phonemes)\n",
        "\n",
        "            # Prepare for CTC loss\n",
        "            # CTC expects: (time, batch, n_classes)\n",
        "            log_probs = F.log_softmax(logits, dim=-1).transpose(0, 1)\n",
        "\n",
        "            # CTC loss\n",
        "            loss = self.ctc_loss(\n",
        "                log_probs=log_probs,\n",
        "                targets=phoneme_ids,\n",
        "                input_lengths=lengths,\n",
        "                target_lengths=seq_lens\n",
        "            )\n",
        "\n",
        "            # Backward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_clip)\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Print progress\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"  Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        return total_loss / max(num_batches, 1)\n",
        "\n",
        "    def validate(self, val_loader: DataLoader) -> float:\n",
        "        \"\"\"Validate the model\"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                # Move to device\n",
        "                neural_features = batch['neural_features'].to(self.device)\n",
        "                phoneme_ids = batch['phoneme_ids'].to(self.device) if batch['phoneme_ids'] is not None else None\n",
        "                lengths = batch['n_time_steps'].to(self.device)\n",
        "                seq_lens = batch['seq_lens'].to(self.device)\n",
        "\n",
        "                # Skip batch if no labels\n",
        "                if phoneme_ids is None:\n",
        "                    continue\n",
        "\n",
        "                # Forward pass\n",
        "                logits = self.model(neural_features, lengths)\n",
        "\n",
        "                # CTC loss\n",
        "                log_probs = F.log_softmax(logits, dim=-1).transpose(0, 1)\n",
        "                loss = self.ctc_loss(log_probs, phoneme_ids, lengths, seq_lens)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "        return total_loss / max(num_batches, 1)\n",
        "\n",
        "    def train(self, train_loader: DataLoader, val_loader: DataLoader = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Full training loop\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with training history\n",
        "        \"\"\"\n",
        "        print(f\"üöÄ Starting training for {self.config.num_epochs} epochs\")\n",
        "        print(f\"üìä Model: {self.model}\")\n",
        "        print(f\"‚öôÔ∏è  Config: {self.config}\")\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "\n",
        "        for epoch in range(self.config.num_epochs):\n",
        "            print(f\"\\nüìÖ Epoch {epoch+1}/{self.config.num_epochs}\")\n",
        "\n",
        "            # Train\n",
        "            train_loss = self.train_epoch(train_loader)\n",
        "            self.train_losses.append(train_loss)\n",
        "\n",
        "            # Validate\n",
        "            val_loss = None\n",
        "            if val_loader is not None:\n",
        "                val_loss = self.validate(val_loader)\n",
        "                self.val_losses.append(val_loss)\n",
        "\n",
        "                # Save best model\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    torch.save(self.model.state_dict(), 'best_model.pt')\n",
        "                    print(f\"üíæ Saved best model (val_loss: {val_loss:.4f})\")\n",
        "\n",
        "            # Update learning rate\n",
        "            self.scheduler.step()\n",
        "\n",
        "            # Print epoch summary\n",
        "            lr = self.optimizer.param_groups[0]['lr']\n",
        "            val_loss_str = f\"{val_loss:.4f}\" if val_loss is not None else \"N/A\"\n",
        "            print(f\"üìà Train Loss: {train_loss:.4f}, Val Loss: {val_loss_str}, LR: {lr:.6f}\")\n",
        "\n",
        "        return {\n",
        "            'train_losses': self.train_losses,\n",
        "            'val_losses': self.val_losses,\n",
        "            'best_val_loss': best_val_loss\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyZ5_vIV8v8u"
      },
      "source": [
        "# SECTION 7: INFERENCE AND EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Aybfent51GG5"
      },
      "outputs": [],
      "source": [
        "class Brain2TextInference:\n",
        "    \"\"\"\n",
        "    Inference and evaluation for Brain-to-Text model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, config: Config):\n",
        "        self.model = model\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        # Move model to device and set to eval mode\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        # Initialize CTC decoder if available\n",
        "        self.ctc_decoder = None\n",
        "        if HAS_CTC_DECODE:\n",
        "            labels = [ID_TO_PHONEME[i] for i in range(N_PHONEMES)]\n",
        "            self.ctc_decoder = ctcdecode.CTCBeamDecoder(\n",
        "                labels=labels,\n",
        "                blank_id=config.blank_id,\n",
        "                beam_width=config.beam_width\n",
        "            )\n",
        "\n",
        "    def decode_batch(self, neural_features: torch.Tensor, lengths: torch.Tensor) -> List[List[str]]:\n",
        "        \"\"\"\n",
        "        Decode a batch of neural features to phoneme sequences\n",
        "\n",
        "        Args:\n",
        "            neural_features: (batch, time, 512) neural data\n",
        "            lengths: (batch,) actual sequence lengths\n",
        "\n",
        "        Returns:\n",
        "            List of phoneme sequences for each sample in batch\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            # Get model predictions\n",
        "            logits = self.model(neural_features, lengths)  # (batch, time, n_phonemes)\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "            # Decode using CTC\n",
        "            if self.ctc_decoder is not None:\n",
        "                # Use beam search decoder\n",
        "                beam_results, beam_scores, timesteps, out_seq_len = self.ctc_decoder.decode(log_probs, lengths)\n",
        "\n",
        "                # Extract best hypothesis for each sample\n",
        "                phoneme_sequences = []\n",
        "                for i in range(beam_results.size(0)):\n",
        "                    # Get best beam (index 0)\n",
        "                    seq_len = out_seq_len[i][0]\n",
        "                    phoneme_ids = beam_results[i][0][:seq_len].tolist()\n",
        "                    phonemes = [ID_TO_PHONEME[pid] for pid in phoneme_ids if pid < len(ID_TO_PHONEME)]\n",
        "                    phoneme_sequences.append(phonemes)\n",
        "\n",
        "                return phoneme_sequences\n",
        "            else:\n",
        "                # Simple greedy decoding\n",
        "                predictions = torch.argmax(log_probs, dim=-1)  # (batch, time)\n",
        "\n",
        "                phoneme_sequences = []\n",
        "                for i, length in enumerate(lengths):\n",
        "                    pred_seq = predictions[i, :length].tolist()\n",
        "\n",
        "                    # Remove blanks and consecutive duplicates (CTC decoding)\n",
        "                    phonemes = []\n",
        "                    prev_pid = None\n",
        "                    for pid in pred_seq:\n",
        "                        if pid != self.config.blank_id and pid != prev_pid:\n",
        "                            if pid < len(ID_TO_PHONEME):\n",
        "                                phonemes.append(ID_TO_PHONEME[pid])\n",
        "                        prev_pid = pid\n",
        "\n",
        "                    phoneme_sequences.append(phonemes)\n",
        "\n",
        "                return phoneme_sequences\n",
        "\n",
        "    def evaluate_dataset(self, data_loader: DataLoader) -> Dict:\n",
        "        \"\"\"\n",
        "        Evaluate model on a dataset\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with evaluation metrics\n",
        "        \"\"\"\n",
        "        print(\"üîç Evaluating model...\")\n",
        "\n",
        "        all_predictions = []\n",
        "        all_targets = []\n",
        "        all_transcriptions = []\n",
        "\n",
        "        for batch in data_loader:\n",
        "            # Move to device\n",
        "            neural_features = batch['neural_features'].to(self.device)\n",
        "            lengths = batch['n_time_steps'].to(self.device)\n",
        "            transcriptions = batch['transcriptions']\n",
        "\n",
        "            # Decode predictions\n",
        "            predicted_phonemes = self.decode_batch(neural_features, lengths)\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predicted_phonemes)\n",
        "            all_transcriptions.extend(transcriptions)\n",
        "\n",
        "            # Store targets if available\n",
        "            if batch['phoneme_ids'] is not None:\n",
        "                for i, seq_len in enumerate(batch['seq_lens']):\n",
        "                    target_ids = batch['phoneme_ids'][i, :seq_len].tolist()\n",
        "                    target_phonemes = [ID_TO_PHONEME[pid] for pid in target_ids if pid < len(ID_TO_PHONEME)]\n",
        "                    all_targets.append(target_phonemes)\n",
        "\n",
        "        # Calculate metrics\n",
        "        results = {\n",
        "            'num_samples': len(all_predictions),\n",
        "            'predictions': all_predictions,\n",
        "            'targets': all_targets if all_targets else None,\n",
        "            'transcriptions': all_transcriptions\n",
        "        }\n",
        "\n",
        "        # Calculate phoneme accuracy if targets available\n",
        "        if all_targets:\n",
        "            phoneme_accuracy = self._calculate_phoneme_accuracy(all_predictions, all_targets)\n",
        "            results['phoneme_accuracy'] = phoneme_accuracy\n",
        "            print(f\"üìä Phoneme Accuracy: {phoneme_accuracy:.3f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _calculate_phoneme_accuracy(self, predictions: List[List[str]], targets: List[List[str]]) -> float:\n",
        "        \"\"\"Calculate phoneme-level accuracy\"\"\"\n",
        "        total_phonemes = 0\n",
        "        correct_phonemes = 0\n",
        "\n",
        "        for pred, target in zip(predictions, targets):\n",
        "            # Align sequences (simple approach)\n",
        "            min_len = min(len(pred), len(target))\n",
        "            total_phonemes += max(len(pred), len(target))\n",
        "\n",
        "            for i in range(min_len):\n",
        "                if pred[i] == target[i]:\n",
        "                    correct_phonemes += 1\n",
        "\n",
        "        return correct_phonemes / max(total_phonemes, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZmiOzSx834j"
      },
      "source": [
        "# SECTION 8: LANGUAGE MODEL INTEGRATION (FULL IMPLEMENTATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ts8RDtQt1F6E"
      },
      "outputs": [],
      "source": [
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear GPU memory for Colab optimization\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "class FullLanguageModel:\n",
        "    \"\"\"\n",
        "    Full language model implementation using OPT-6.7B + comprehensive n-gram\n",
        "    Optimized for Google Colab with memory management\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_opt: bool = True, use_fallback: bool = True):\n",
        "        self.use_opt = use_opt\n",
        "        self.use_fallback = use_fallback\n",
        "        self.device = device\n",
        "\n",
        "        # Initialize comprehensive phoneme dictionary\n",
        "        self.phoneme_dict = self._build_comprehensive_phoneme_dictionary()\n",
        "\n",
        "        # Build n-gram patterns\n",
        "        self.ngram_patterns = self._build_ngram_patterns()\n",
        "\n",
        "        # Initialize OPT-6.7B\n",
        "        self.opt_model = None\n",
        "        self.opt_tokenizer = None\n",
        "        self.fallback_model = None\n",
        "\n",
        "        if HAS_TRANSFORMERS:\n",
        "            self._initialize_language_models()\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  Transformers not available. Using basic phoneme mapping only.\")\n",
        "\n",
        "    def _initialize_language_models(self):\n",
        "        \"\"\"Initialize language models with memory optimization\"\"\"\n",
        "        try:\n",
        "            if self.use_opt:\n",
        "                print(\"ü§ñ Loading OPT-6.7B model (this may take a few minutes)...\")\n",
        "\n",
        "                # Clear memory first\n",
        "                clear_gpu_memory()\n",
        "\n",
        "                # Load with memory optimization\n",
        "                self.opt_tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-6.7b\")\n",
        "                self.opt_model = AutoModelForCausalLM.from_pretrained(\n",
        "                    \"facebook/opt-6.7b\",\n",
        "                    torch_dtype=torch.float16,  # Half precision to save VRAM\n",
        "                    device_map=\"auto\",  # Automatic device placement\n",
        "                    low_cpu_mem_usage=True,  # Optimize CPU memory usage\n",
        "                )\n",
        "\n",
        "                # Ensure padding token\n",
        "                if self.opt_tokenizer.pad_token is None:\n",
        "                    self.opt_tokenizer.pad_token = self.opt_tokenizer.eos_token\n",
        "\n",
        "                self.opt_model.eval()\n",
        "                print(\"‚úÖ OPT-6.7B loaded successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Failed to load OPT-6.7B: {e}\")\n",
        "            self.use_opt = False\n",
        "\n",
        "        # Initialize fallback model if OPT fails or not requested\n",
        "        if self.use_fallback and (not self.use_opt or self.opt_model is None):\n",
        "            try:\n",
        "                print(\"ü§ñ Loading fallback model (GPT-2 Medium)...\")\n",
        "                self.fallback_model = pipeline(\n",
        "                    \"text-generation\",\n",
        "                    model=\"gpt2-medium\",\n",
        "                    device=0 if torch.cuda.is_available() else -1,\n",
        "                    torch_dtype=torch.float16\n",
        "                )\n",
        "                print(\"‚úÖ Fallback model loaded successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è  Failed to load fallback model: {e}\")\n",
        "                self.fallback_model = None\n",
        "\n",
        "    def _build_comprehensive_phoneme_dictionary(self) -> Dict:\n",
        "        \"\"\"Build comprehensive phoneme-to-word mapping\"\"\"\n",
        "        return {\n",
        "            # Articles and determiners\n",
        "            ('DH', 'AH'): ['the'],\n",
        "            ('AH'): ['a'],\n",
        "            ('AE', 'N'): ['an'],\n",
        "\n",
        "            # Common pronouns\n",
        "            ('AY'): ['I'],\n",
        "            ('Y', 'UW'): ['you'],\n",
        "            ('HH', 'IY'): ['he'],\n",
        "            ('SH', 'IY'): ['she'],\n",
        "            ('IH', 'T'): ['it'],\n",
        "            ('W', 'IY'): ['we'],\n",
        "            ('DH', 'EY'): ['they'],\n",
        "\n",
        "            # Common verbs\n",
        "            ('IH', 'Z'): ['is'],\n",
        "            ('AA', 'R'): ['are'],\n",
        "            ('W', 'AA', 'Z'): ['was'],\n",
        "            ('W', 'ER'): ['were'],\n",
        "            ('HH', 'AE', 'V'): ['have'],\n",
        "            ('HH', 'AE', 'Z'): ['has'],\n",
        "            ('HH', 'AE', 'D'): ['had'],\n",
        "            ('W', 'IH', 'L'): ['will'],\n",
        "            ('K', 'AE', 'N'): ['can'],\n",
        "            ('K', 'UH', 'D'): ['could'],\n",
        "            ('SH', 'UH', 'D'): ['should'],\n",
        "            ('W', 'UH', 'D'): ['would'],\n",
        "            ('D', 'UW'): ['do'],\n",
        "            ('D', 'AH', 'Z'): ['does'],\n",
        "            ('D', 'IH', 'D'): ['did'],\n",
        "            ('G', 'OW'): ['go'],\n",
        "            ('K', 'AH', 'M'): ['come'],\n",
        "            ('G', 'EH', 'T'): ['get'],\n",
        "            ('M', 'EY', 'K'): ['make'],\n",
        "            ('T', 'EY', 'K'): ['take'],\n",
        "            ('S', 'IY'): ['see'],\n",
        "            ('N', 'OW'): ['know'],\n",
        "            ('TH', 'IH', 'NG', 'K'): ['think'],\n",
        "\n",
        "            # Common nouns\n",
        "            ('T', 'AY', 'M'): ['time'],\n",
        "            ('P', 'ER', 'S', 'AH', 'N'): ['person'],\n",
        "            ('Y', 'IH', 'R'): ['year'],\n",
        "            ('W', 'EY'): ['way'],\n",
        "            ('D', 'EY'): ['day'],\n",
        "            ('M', 'AE', 'N'): ['man'],\n",
        "            ('TH', 'IH', 'NG'): ['thing'],\n",
        "            ('W', 'UH', 'M', 'AH', 'N'): ['woman'],\n",
        "            ('L', 'AY', 'F'): ['life'],\n",
        "            ('CH', 'AY', 'L', 'D'): ['child'],\n",
        "            ('W', 'ER', 'L', 'D'): ['world'],\n",
        "            ('S', 'K', 'UW', 'L'): ['school'],\n",
        "            ('S', 'T', 'EY', 'T'): ['state'],\n",
        "            ('F', 'AE', 'M', 'L', 'IY'): ['family'],\n",
        "            ('S', 'T', 'UW', 'D', 'AH', 'N', 'T'): ['student'],\n",
        "            ('G', 'R', 'UW', 'P'): ['group'],\n",
        "            ('K', 'AH', 'N', 'T', 'R', 'IY'): ['country'],\n",
        "            ('P', 'R', 'AA', 'B', 'L', 'AH', 'M'): ['problem'],\n",
        "            ('HH', 'AE', 'N', 'D'): ['hand'],\n",
        "            ('R', 'AY', 'T'): ['right'],\n",
        "            ('S', 'IH', 'S', 'T', 'AH', 'M'): ['system'],\n",
        "\n",
        "            # Prepositions and conjunctions\n",
        "            ('IH', 'N'): ['in'],\n",
        "            ('AA', 'N'): ['on'],\n",
        "            ('AE', 'T'): ['at'],\n",
        "            ('B', 'AY'): ['by'],\n",
        "            ('F', 'AO', 'R'): ['for'],\n",
        "            ('W', 'IH', 'TH'): ['with'],\n",
        "            ('AH', 'V'): ['of'],\n",
        "            ('T', 'UW'): ['to'],\n",
        "            ('F', 'R', 'AH', 'M'): ['from'],\n",
        "            ('AH', 'P'): ['up'],\n",
        "            ('AW', 'T'): ['out'],\n",
        "            ('AH', 'B', 'AW', 'T'): ['about'],\n",
        "            ('IH', 'N', 'T', 'UW'): ['into'],\n",
        "            ('OW', 'V', 'ER'): ['over'],\n",
        "            ('AE', 'F', 'T', 'ER'): ['after'],\n",
        "            ('AH', 'N', 'D'): ['and'],\n",
        "            ('B', 'AH', 'T'): ['but'],\n",
        "            ('AO', 'R'): ['or'],\n",
        "            ('S', 'OW'): ['so'],\n",
        "            ('IH', 'F'): ['if'],\n",
        "            ('DH', 'AE', 'N'): ['than'],\n",
        "            ('W', 'EH', 'N'): ['when'],\n",
        "            ('W', 'EH', 'R'): ['where'],\n",
        "            ('W', 'AY'): ['why'],\n",
        "            ('HH', 'AW'): ['how'],\n",
        "\n",
        "            # Common adjectives\n",
        "            ('G', 'UH', 'D'): ['good'],\n",
        "            ('N', 'UW'): ['new'],\n",
        "            ('F', 'ER', 'S', 'T'): ['first'],\n",
        "            ('L', 'AE', 'S', 'T'): ['last'],\n",
        "            ('L', 'AO', 'NG'): ['long'],\n",
        "            ('G', 'R', 'EY', 'T'): ['great'],\n",
        "            ('L', 'IH', 'T', 'AH', 'L'): ['little'],\n",
        "            ('OW', 'N'): ['own'],\n",
        "            ('AH', 'DH', 'ER'): ['other'],\n",
        "            ('OW', 'L', 'D'): ['old'],\n",
        "            ('R', 'AY', 'T'): ['right'],\n",
        "            ('B', 'IH', 'G'): ['big'],\n",
        "            ('HH', 'AY'): ['high'],\n",
        "            ('D', 'IH', 'F', 'R', 'AH', 'N', 'T'): ['different'],\n",
        "            ('S', 'M', 'AO', 'L'): ['small'],\n",
        "            ('L', 'AA', 'R', 'JH'): ['large'],\n",
        "            ('N', 'EH', 'K', 'S', 'T'): ['next'],\n",
        "            ('ER', 'L', 'IY'): ['early'],\n",
        "            ('Y', 'AH', 'NG'): ['young'],\n",
        "            ('IH', 'M', 'P', 'AO', 'R', 'T', 'AH', 'N', 'T'): ['important'],\n",
        "\n",
        "            # Numbers\n",
        "            ('W', 'AH', 'N'): ['one'],\n",
        "            ('T', 'UW'): ['two'],\n",
        "            ('TH', 'R', 'IY'): ['three'],\n",
        "            ('F', 'AO', 'R'): ['four'],\n",
        "            ('F', 'AY', 'V'): ['five'],\n",
        "            ('S', 'IH', 'K', 'S'): ['six'],\n",
        "            ('S', 'EH', 'V', 'AH', 'N'): ['seven'],\n",
        "            ('EY', 'T'): ['eight'],\n",
        "            ('N', 'AY', 'N'): ['nine'],\n",
        "            ('T', 'EH', 'N'): ['ten'],\n",
        "\n",
        "            # Medical/Clinical terms (relevant for neural data)\n",
        "            ('P', 'EY', 'SH', 'AH', 'N', 'T'): ['patient'],\n",
        "            ('D', 'AA', 'K', 'T', 'ER'): ['doctor'],\n",
        "            ('N', 'ER', 'S'): ['nurse'],\n",
        "            ('HH', 'AA', 'S', 'P', 'IH', 'T', 'AH', 'L'): ['hospital'],\n",
        "            ('T', 'R', 'IY', 'T', 'M', 'AH', 'N', 'T'): ['treatment'],\n",
        "            ('M', 'EH', 'D', 'AH', 'S', 'AH', 'N'): ['medicine'],\n",
        "            ('S', 'ER', 'JH', 'ER', 'IY'): ['surgery'],\n",
        "            ('TH', 'EH', 'R', 'AH', 'P', 'IY'): ['therapy'],\n",
        "            ('D', 'AY', 'AH', 'G', 'N', 'OW', 'S', 'IH', 'S'): ['diagnosis'],\n",
        "            ('S', 'IH', 'M', 'T', 'AH', 'M'): ['symptom'],\n",
        "            ('K', 'AO', 'N', 'D', 'IH', 'SH', 'AH', 'N'): ['condition'],\n",
        "            ('R', 'IH', 'K', 'AH', 'V', 'ER', 'IY'): ['recovery'],\n",
        "            ('HH', 'EH', 'L', 'TH'): ['health'],\n",
        "            ('K', 'EH', 'R'): ['care'],\n",
        "\n",
        "            # Common phrases and contractions\n",
        "            ('D', 'OW', 'N', 'T'): [\"don't\"],\n",
        "            ('K', 'AE', 'N', 'T'): [\"can't\"],\n",
        "            ('W', 'OW', 'N', 'T'): [\"won't\"],\n",
        "            ('IH', 'T', 'S'): [\"it's\"],\n",
        "            ('DH', 'AE', 'T', 'S'): [\"that's\"],\n",
        "            ('W', 'AH', 'T', 'S'): [\"what's\"],\n",
        "            ('HH', 'IY', 'Z'): [\"he's\"],\n",
        "            ('SH', 'IY', 'Z'): [\"she's\"],\n",
        "            ('DH', 'EH', 'R', 'Z'): [\"there's\"],\n",
        "            ('HH', 'IH', 'R', 'Z'): [\"here's\"],\n",
        "            ('L', 'EH', 'T', 'S'): [\"let's\"],\n",
        "            ('AY', 'M'): [\"I'm\"],\n",
        "            ('Y', 'UH', 'R'): [\"you're\"],\n",
        "            ('W', 'IY', 'R'): [\"we're\"],\n",
        "            ('DH', 'EY', 'R'): [\"they're\"],\n",
        "            ('AY', 'V'): [\"I've\"],\n",
        "            ('Y', 'UH', 'V'): [\"you've\"],\n",
        "            ('W', 'IY', 'V'): [\"we've\"],\n",
        "            ('DH', 'EY', 'V'): [\"they've\"],\n",
        "            ('AY', 'L'): [\"I'll\"],\n",
        "            ('Y', 'UH', 'L'): [\"you'll\"],\n",
        "            ('HH', 'IY', 'L'): [\"he'll\"],\n",
        "            ('SH', 'IY', 'L'): [\"she'll\"],\n",
        "            ('W', 'IY', 'L'): [\"we'll\"],\n",
        "            ('DH', 'EY', 'L'): [\"they'll\"],\n",
        "        }\n",
        "\n",
        "    def _build_ngram_patterns(self) -> Dict:\n",
        "        \"\"\"Build n-gram patterns for context-aware word prediction\"\"\"\n",
        "        return {\n",
        "            # Common 2-gram patterns\n",
        "            ('the',): {\n",
        "                'patient': 0.15, 'doctor': 0.08, 'hospital': 0.05, 'treatment': 0.04,\n",
        "                'first': 0.06, 'last': 0.04, 'next': 0.03, 'same': 0.03,\n",
        "                'right': 0.04, 'left': 0.03, 'best': 0.03, 'most': 0.05,\n",
        "                'other': 0.04, 'new': 0.04, 'old': 0.03, 'young': 0.02,\n",
        "                'time': 0.03, 'way': 0.03, 'world': 0.02, 'country': 0.02,\n",
        "                'system': 0.02, 'problem': 0.03, 'question': 0.02, 'answer': 0.02\n",
        "            },\n",
        "            ('patient', 'was'): {\n",
        "                'admitted': 0.25, 'discharged': 0.15, 'treated': 0.12, 'examined': 0.10,\n",
        "                'diagnosed': 0.08, 'transferred': 0.06, 'stable': 0.05, 'critical': 0.04,\n",
        "                'recovering': 0.08, 'improving': 0.07\n",
        "            },\n",
        "            ('the', 'patient'): {\n",
        "                'was': 0.30, 'is': 0.25, 'has': 0.15, 'had': 0.10, 'will': 0.08,\n",
        "                'needs': 0.05, 'requires': 0.04, 'underwent': 0.03\n",
        "            },\n",
        "            ('doctor', 'said'): {\n",
        "                'the': 0.20, 'that': 0.30, 'he': 0.10, 'she': 0.10, 'it': 0.08,\n",
        "                'we': 0.07, 'they': 0.05, 'this': 0.05, 'everything': 0.05\n",
        "            },\n",
        "            ('in', 'the'): {\n",
        "                'hospital': 0.15, 'morning': 0.08, 'evening': 0.06, 'afternoon': 0.05,\n",
        "                'room': 0.10, 'bed': 0.08, 'clinic': 0.06, 'office': 0.05,\n",
        "                'emergency': 0.04, 'surgery': 0.05, 'recovery': 0.04, 'ward': 0.06,\n",
        "                'future': 0.03, 'past': 0.02, 'present': 0.02, 'beginning': 0.03,\n",
        "                'end': 0.03, 'middle': 0.02, 'center': 0.03, 'area': 0.03\n",
        "            },\n",
        "            ('will', 'be'): {\n",
        "                'able': 0.15, 'ready': 0.10, 'available': 0.08, 'necessary': 0.06,\n",
        "                'important': 0.05, 'difficult': 0.04, 'easy': 0.04, 'possible': 0.08,\n",
        "                'discharged': 0.06, 'transferred': 0.04, 'treated': 0.05, 'examined': 0.04,\n",
        "                'fine': 0.05, 'okay': 0.04, 'better': 0.06, 'worse': 0.03,\n",
        "                'there': 0.05, 'here': 0.04, 'back': 0.04\n",
        "            },\n",
        "            ('I', 'am'): {\n",
        "                'going': 0.15, 'not': 0.12, 'very': 0.08, 'so': 0.06, 'really': 0.05,\n",
        "                'here': 0.06, 'there': 0.04, 'fine': 0.08, 'okay': 0.06, 'good': 0.07,\n",
        "                'sorry': 0.05, 'happy': 0.04, 'sad': 0.03, 'tired': 0.04,\n",
        "                'ready': 0.05, 'sure': 0.06\n",
        "            },\n",
        "            ('you', 'are'): {\n",
        "                'going': 0.12, 'not': 0.10, 'very': 0.08, 'so': 0.06, 'really': 0.05,\n",
        "                'right': 0.08, 'wrong': 0.04, 'correct': 0.05, 'welcome': 0.06,\n",
        "                'fine': 0.08, 'okay': 0.06, 'good': 0.07, 'ready': 0.05,\n",
        "                'sure': 0.06, 'here': 0.04, 'there': 0.04\n",
        "            },\n",
        "            ('this', 'is'): {\n",
        "                'a': 0.20, 'the': 0.15, 'not': 0.10, 'very': 0.08, 'really': 0.06,\n",
        "                'important': 0.08, 'good': 0.06, 'bad': 0.04, 'great': 0.05,\n",
        "                'my': 0.05, 'our': 0.04, 'your': 0.04, 'his': 0.02, 'her': 0.03\n",
        "            },\n",
        "            ('it', 'is'): {\n",
        "                'a': 0.15, 'the': 0.10, 'not': 0.12, 'very': 0.10, 'really': 0.08,\n",
        "                'important': 0.08, 'good': 0.06, 'bad': 0.04, 'great': 0.05,\n",
        "                'possible': 0.06, 'necessary': 0.05, 'difficult': 0.04, 'easy': 0.04,\n",
        "                'time': 0.03\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def phonemes_to_text_candidates(self, phoneme_sequence: List[str], n_candidates: int = 5) -> List[str]:\n",
        "        \"\"\"\n",
        "        Convert phoneme sequence to multiple text candidates using comprehensive dictionary\n",
        "        \"\"\"\n",
        "        if not phoneme_sequence:\n",
        "            return [\"\"]\n",
        "\n",
        "        candidates = set()\n",
        "\n",
        "        # Method 1: Greedy longest-match decoding\n",
        "        words = []\n",
        "        i = 0\n",
        "        while i < len(phoneme_sequence):\n",
        "            matched = False\n",
        "            # Try longest matches first (up to 8 phonemes)\n",
        "            for length in range(min(8, len(phoneme_sequence) - i), 0, -1):\n",
        "                phoneme_tuple = tuple(phoneme_sequence[i:i+length])\n",
        "                if phoneme_tuple in self.phoneme_dict:\n",
        "                    word_options = self.phoneme_dict[phoneme_tuple]\n",
        "                    words.append(word_options[0])  # Take first option\n",
        "                    i += length\n",
        "                    matched = True\n",
        "                    break\n",
        "\n",
        "            if not matched:\n",
        "                i += 1  # Skip unknown phoneme\n",
        "\n",
        "        if words:\n",
        "            base_text = ' '.join(words)\n",
        "            candidates.add(base_text)\n",
        "\n",
        "            # Generate variations by using alternative word choices\n",
        "            for alt_idx in range(min(3, len(words))):\n",
        "                alt_words = words.copy()\n",
        "                # Try to find alternative for this position\n",
        "                phoneme_start = 0\n",
        "                for w_idx, word in enumerate(words):\n",
        "                    if w_idx == alt_idx:\n",
        "                        # Find phoneme sequence for this word\n",
        "                        for phoneme_tuple, word_list in self.phoneme_dict.items():\n",
        "                            if word in word_list and len(word_list) > 1:\n",
        "                                # Use alternative word\n",
        "                                alt_words[w_idx] = word_list[1 if word_list[0] == word else 0]\n",
        "                                break\n",
        "                        break\n",
        "\n",
        "                alt_text = ' '.join(alt_words)\n",
        "                if alt_text != base_text:\n",
        "                    candidates.add(alt_text)\n",
        "\n",
        "        # Method 2: Use n-gram patterns to generate contextual candidates\n",
        "        if len(candidates) > 0:\n",
        "            base_words = list(candidates)[0].split()\n",
        "\n",
        "            # Try to extend or modify using n-gram patterns\n",
        "            for i in range(len(base_words)):\n",
        "                if i < len(base_words) - 1:\n",
        "                    context = (base_words[i],)\n",
        "                    if context in self.ngram_patterns:\n",
        "                        for next_word, prob in list(self.ngram_patterns[context].items())[:3]:\n",
        "                            new_words = base_words.copy()\n",
        "                            if i + 1 < len(new_words):\n",
        "                                new_words[i + 1] = next_word\n",
        "                            else:\n",
        "                                new_words.append(next_word)\n",
        "                            candidates.add(' '.join(new_words))\n",
        "\n",
        "        # Convert to list and ensure we have enough candidates\n",
        "        candidate_list = list(candidates)\n",
        "\n",
        "        # If we don't have enough candidates, create variations\n",
        "        while len(candidate_list) < n_candidates and candidate_list:\n",
        "            base = candidate_list[0]\n",
        "            # Add simple variations\n",
        "            variations = [\n",
        "                base.replace(' the ', ' a '),\n",
        "                base.replace(' is ', ' was '),\n",
        "                base.replace(' are ', ' were '),\n",
        "                base.replace(' will ', ' would '),\n",
        "                base.replace(' can ', ' could ')\n",
        "            ]\n",
        "\n",
        "            for var in variations:\n",
        "                if var != base and var not in candidate_list:\n",
        "                    candidate_list.append(var)\n",
        "                    if len(candidate_list) >= n_candidates:\n",
        "                        break\n",
        "\n",
        "        # Pad with empty strings if needed\n",
        "        while len(candidate_list) < n_candidates:\n",
        "            candidate_list.append(candidate_list[0] if candidate_list else \"unknown\")\n",
        "\n",
        "        return candidate_list[:n_candidates]\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def rescore_with_opt(self, text_candidates: List[str]) -> str:\n",
        "        \"\"\"\n",
        "        Rescore text candidates using OPT-6.7B and return best one\n",
        "        \"\"\"\n",
        "        if not text_candidates:\n",
        "            return \"unknown\"\n",
        "\n",
        "        # Filter out empty candidates\n",
        "        valid_candidates = [c for c in text_candidates if c.strip()]\n",
        "        if not valid_candidates:\n",
        "            return \"unknown\"\n",
        "\n",
        "        # If OPT is not available, use simple heuristics\n",
        "        if not self.use_opt or self.opt_model is None:\n",
        "            return self._simple_candidate_selection(valid_candidates)\n",
        "\n",
        "        try:\n",
        "            scores = []\n",
        "\n",
        "            for text in valid_candidates:\n",
        "                try:\n",
        "                    # Tokenize with proper handling\n",
        "                    inputs = self.opt_tokenizer(\n",
        "                        text,\n",
        "                        return_tensors=\"pt\",\n",
        "                        truncation=True,\n",
        "                        max_length=256,  # Shorter for memory efficiency\n",
        "                        padding=False\n",
        "                    )\n",
        "\n",
        "                    # Move to device\n",
        "                    inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "                    # Get model predictions\n",
        "                    with torch.cuda.amp.autocast():  # Use mixed precision\n",
        "                        outputs = self.opt_model(**inputs)\n",
        "\n",
        "                    # Calculate perplexity (lower is better, so we negate for scoring)\n",
        "                    log_probs = torch.nn.functional.log_softmax(outputs.logits, dim=-1)\n",
        "\n",
        "                    # Get probability of the actual tokens\n",
        "                    input_ids = inputs['input_ids'][0]\n",
        "                    total_log_prob = 0\n",
        "\n",
        "                    for i in range(1, len(input_ids)):  # Skip first token\n",
        "                        if i - 1 < log_probs.size(1):\n",
        "                            token_log_prob = log_probs[0, i-1, input_ids[i]]\n",
        "                            total_log_prob += token_log_prob.item()\n",
        "\n",
        "                    # Average log probability (higher is better)\n",
        "                    avg_log_prob = total_log_prob / max(len(input_ids) - 1, 1)\n",
        "\n",
        "                    # Add length penalty (prefer reasonable length)\n",
        "                    length_penalty = -abs(len(input_ids) - 10) * 0.01  # Prefer ~10 tokens\n",
        "\n",
        "                    final_score = avg_log_prob + length_penalty\n",
        "                    scores.append(final_score)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error scoring '{text[:50]}...': {e}\")\n",
        "                    scores.append(-float('inf'))\n",
        "\n",
        "            # Return candidate with highest score\n",
        "            if scores:\n",
        "                best_idx = np.argmax(scores)\n",
        "                return valid_candidates[best_idx]\n",
        "            else:\n",
        "                return valid_candidates[0]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in OPT rescoring: {e}\")\n",
        "            return self._simple_candidate_selection(valid_candidates)\n",
        "\n",
        "    def _simple_candidate_selection(self, candidates: List[str]) -> str:\n",
        "        \"\"\"\n",
        "        Simple candidate selection based on heuristics when OPT is not available\n",
        "        \"\"\"\n",
        "        if not candidates:\n",
        "            return \"unknown\"\n",
        "\n",
        "        # Score candidates based on simple heuristics\n",
        "        scores = []\n",
        "\n",
        "        for candidate in candidates:\n",
        "            score = 0\n",
        "            words = candidate.lower().split()\n",
        "\n",
        "            # Prefer reasonable length\n",
        "            if 3 <= len(words) <= 15:\n",
        "                score += 2\n",
        "            elif 1 <= len(words) <= 20:\n",
        "                score += 1\n",
        "\n",
        "            # Prefer common words\n",
        "            common_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n",
        "            score += sum(1 for word in words if word in common_words)\n",
        "\n",
        "            # Prefer medical/clinical terms if present\n",
        "            medical_words = {'patient', 'doctor', 'hospital', 'treatment', 'medicine', 'therapy', 'diagnosis'}\n",
        "            score += sum(2 for word in words if word in medical_words)\n",
        "\n",
        "            # Penalize very short or very long candidates\n",
        "            if len(words) < 2:\n",
        "                score -= 1\n",
        "            if len(words) > 20:\n",
        "                score -= 2\n",
        "\n",
        "            scores.append(score)\n",
        "\n",
        "        # Return candidate with highest score\n",
        "        best_idx = np.argmax(scores) if scores else 0\n",
        "        return candidates[best_idx]\n",
        "\n",
        "    def phonemes_to_text(self, phoneme_sequences: List[List[str]]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Convert phoneme sequences to text using full pipeline\n",
        "        \"\"\"\n",
        "        import time\n",
        "        from tqdm import tqdm\n",
        "\n",
        "        texts = []\n",
        "        start_time = time.time()\n",
        "\n",
        "        print(f\"üîÑ Converting {len(phoneme_sequences)} phoneme sequences to text...\")\n",
        "        print(\"‚ö†Ô∏è  This is VERY slow with OPT-6.7B (~3-5 seconds per sequence)\")\n",
        "\n",
        "        # Use tqdm for better progress tracking\n",
        "        progress_bar = tqdm(phoneme_sequences, desc=\"Converting phonemes to text\")\n",
        "\n",
        "        for i, phonemes in enumerate(progress_bar):\n",
        "            sequence_start = time.time()\n",
        "\n",
        "            # Generate multiple candidates\n",
        "            candidates = self.phonemes_to_text_candidates(phonemes, n_candidates=3)  # Reduced from 5\n",
        "\n",
        "            # Rescore with language model\n",
        "            best_text = self.rescore_with_opt(candidates)\n",
        "            texts.append(best_text)\n",
        "\n",
        "            sequence_time = time.time() - sequence_start\n",
        "\n",
        "            # Update progress bar with timing info\n",
        "            if i > 0:\n",
        "                avg_time = (time.time() - start_time) / (i + 1)\n",
        "                remaining = len(phoneme_sequences) - (i + 1)\n",
        "                eta_minutes = (remaining * avg_time) / 60\n",
        "                progress_bar.set_postfix({\n",
        "                    'avg_time': f'{avg_time:.2f}s/seq',\n",
        "                    'ETA': f'{eta_minutes:.1f}min'\n",
        "                })\n",
        "\n",
        "            # Early warning system\n",
        "            if i == 4:  # After just 5 sequences\n",
        "                elapsed = time.time() - start_time\n",
        "                avg_time_per_seq = elapsed / 5\n",
        "                if avg_time_per_seq > 3:  # If >3 seconds per sequence\n",
        "                    total_eta_minutes = (len(phoneme_sequences) * avg_time_per_seq) / 60\n",
        "                    print(f\"\\n‚ö†Ô∏è  WARNING: Very slow processing detected after 5 samples!\")\n",
        "                    print(f\"‚ö†Ô∏è  Current speed: {avg_time_per_seq:.2f}s per sequence\")\n",
        "                    print(f\"‚ö†Ô∏è  Estimated total time: {total_eta_minutes:.0f} minutes ({total_eta_minutes/60:.1f} hours)\")\n",
        "                    print(f\"üí° RECOMMENDATION: Stop and restart with skip_full_evaluation=True\")\n",
        "                    print(f\"üí° Or use max_eval_samples=50 for faster results\")\n",
        "\n",
        "            # Periodic memory cleanup and progress updates\n",
        "            if (i + 1) % 10 == 0:\n",
        "                clear_gpu_memory()\n",
        "\n",
        "        elapsed_total = time.time() - start_time\n",
        "        print(f\"‚úÖ Phoneme-to-text conversion complete in {elapsed_total/60:.1f} minutes\")\n",
        "        print(f\"üìä Average time per sequence: {elapsed_total/len(phoneme_sequences):.2f}s\")\n",
        "\n",
        "        return texts\n",
        "\n",
        "# Simple fallback language model for basic functionality\n",
        "class SimpleLanguageModel:\n",
        "    \"\"\"\n",
        "    Simplified language model for phoneme-to-text conversion\n",
        "    Fallback when full model is not available\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Basic phoneme-to-word mapping\n",
        "        self.phoneme_to_word = {\n",
        "            ('DH', 'AH'): 'the',\n",
        "            ('DH', 'AE', 'T'): 'that',\n",
        "            ('DH', 'IH', 'S'): 'this',\n",
        "            ('AH', 'N', 'D'): 'and',\n",
        "            ('W', 'IH', 'TH'): 'with',\n",
        "            ('F', 'AO', 'R'): 'for',\n",
        "            ('Y', 'UW'): 'you',\n",
        "            ('IH', 'T'): 'it',\n",
        "            ('IH', 'N'): 'in',\n",
        "            ('T', 'UW'): 'to',\n",
        "            ('AH', 'V'): 'of',\n",
        "            ('P', 'EY', 'SH', 'AH', 'N', 'T'): 'patient',\n",
        "            ('D', 'AA', 'K', 'T', 'ER'): 'doctor',\n",
        "            ('HH', 'AA', 'S', 'P', 'IH', 'T', 'AH', 'L'): 'hospital',\n",
        "        }\n",
        "\n",
        "    def phonemes_to_text(self, phoneme_sequences: List[List[str]]) -> List[str]:\n",
        "        \"\"\"Convert phoneme sequences to text using basic mapping\"\"\"\n",
        "        texts = []\n",
        "\n",
        "        for phonemes in phoneme_sequences:\n",
        "            words = []\n",
        "            i = 0\n",
        "\n",
        "            while i < len(phonemes):\n",
        "                matched = False\n",
        "                for length in range(min(6, len(phonemes) - i), 0, -1):\n",
        "                    phoneme_tuple = tuple(phonemes[i:i+length])\n",
        "                    if phoneme_tuple in self.phoneme_to_word:\n",
        "                        words.append(self.phoneme_to_word[phoneme_tuple])\n",
        "                        i += length\n",
        "                        matched = True\n",
        "                        break\n",
        "\n",
        "                if not matched:\n",
        "                    i += 1\n",
        "\n",
        "            texts.append(' '.join(words) if words else 'unknown')\n",
        "\n",
        "        return texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gRCKJwZ9Czc"
      },
      "source": [
        "# SECTION 9: EVALUATION METRICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ipNieGaQ83Ya"
      },
      "outputs": [],
      "source": [
        "def calculate_wer(predictions: List[str], targets: List[str]) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Word Error Rate (WER)\n",
        "\n",
        "    WER = (Substitutions + Insertions + Deletions) / Total_Words_in_Reference\n",
        "    \"\"\"\n",
        "    if not targets or not predictions:\n",
        "        return 1.0\n",
        "\n",
        "    total_errors = 0\n",
        "    total_words = 0\n",
        "\n",
        "    for pred, target in zip(predictions, targets):\n",
        "        if not target:\n",
        "            continue\n",
        "\n",
        "        pred_words = pred.lower().split()\n",
        "        target_words = target.lower().split()\n",
        "\n",
        "        total_words += len(target_words)\n",
        "\n",
        "        # Simple edit distance calculation\n",
        "        errors = abs(len(pred_words) - len(target_words))  # Insertions/deletions\n",
        "\n",
        "        # Count substitutions\n",
        "        min_len = min(len(pred_words), len(target_words))\n",
        "        for i in range(min_len):\n",
        "            if pred_words[i] != target_words[i]:\n",
        "                errors += 1\n",
        "\n",
        "        total_errors += errors\n",
        "\n",
        "    return total_errors / max(total_words, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwQ6Oqvx9I4H"
      },
      "source": [
        "# SECTION 10: MAIN TRAINING AND EVALUATION PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MtRDI_ME83Vd"
      },
      "outputs": [],
      "source": [
        "def main_training_pipeline(\n",
        "    data_dir: str,\n",
        "    output_dir: str = \"/content/brain2text_output\",\n",
        "    max_epochs: int = 10,\n",
        "    batch_size: int = None,\n",
        "    learning_rate: float = 1e-3,\n",
        "    use_simple_lm: bool = True,\n",
        "    use_length_grouping: bool = True,\n",
        "    bucket_boundaries: list = None,\n",
        "    skip_full_evaluation: bool = False,\n",
        "    max_eval_samples: int = 100\n",
        "):\n",
        "    \"\"\"\n",
        "    Complete training and evaluation pipeline with memory optimization\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing HDF5 files\n",
        "        output_dir: Directory to save outputs\n",
        "        max_epochs: Number of training epochs\n",
        "        batch_size: Batch size (defaults to config value)\n",
        "        learning_rate: Learning rate\n",
        "        use_simple_lm: Whether to use simple language model\n",
        "        use_length_grouping: Whether to use length-based grouping\n",
        "        bucket_boundaries: Boundaries for length buckets\n",
        "        skip_full_evaluation: Skip full language model evaluation (saves time)\n",
        "        max_eval_samples: Maximum samples to evaluate with full LM\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üß† BRAIN-TO-TEXT 2025: MEMORY-OPTIMIZED TRAINING PIPELINE\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Update config with provided parameters\n",
        "    if batch_size is not None:\n",
        "        config.batch_size = batch_size\n",
        "    config.learning_rate = learning_rate\n",
        "    config.num_epochs = max_epochs\n",
        "\n",
        "    if bucket_boundaries is None:\n",
        "        bucket_boundaries = [500, 1000, 1500, 2000, 3000]\n",
        "\n",
        "    print(f\"üîß Configuration:\")\n",
        "    print(f\"   Batch size: {config.batch_size}\")\n",
        "    print(f\"   Learning rate: {config.learning_rate}\")\n",
        "    print(f\"   Max epochs: {max_epochs}\")\n",
        "    print(f\"   Length grouping: {use_length_grouping}\")\n",
        "    print(f\"   Bucket boundaries: {bucket_boundaries}\")\n",
        "    print(f\"   Skip full evaluation: {skip_full_evaluation}\")\n",
        "    print(f\"   Max eval samples: {max_eval_samples}\")\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load datasets using official train/val splits\n",
        "    print(\"\\nüìÅ Loading datasets...\")\n",
        "    train_dataset = Brain2TextDataset(data_dir, split='train', config=config)\n",
        "    val_dataset = Brain2TextDataset(data_dir, split='val', config=config)\n",
        "\n",
        "    print(f\"üìä Train samples: {len(train_dataset)}\")\n",
        "    print(f\"üìä Val samples: {len(val_dataset)}\")\n",
        "\n",
        "    if use_length_grouping:\n",
        "        print(\"\\nüìè Analyzing sequence lengths...\")\n",
        "\n",
        "        # Analyze sequence lengths for training data\n",
        "        train_lengths = analyze_sequence_lengths(train_dataset)\n",
        "\n",
        "        # Create length buckets for training data\n",
        "        train_buckets = create_length_buckets(train_dataset, bucket_boundaries)\n",
        "\n",
        "        # Create length buckets for validation data\n",
        "        val_buckets = create_length_buckets(val_dataset, bucket_boundaries)\n",
        "\n",
        "        # Create length-grouped data loaders\n",
        "        print(\"\\nüîÑ Creating length-grouped data loaders...\")\n",
        "        train_loader = create_length_grouped_dataloader(\n",
        "            train_dataset,\n",
        "            config.batch_size,\n",
        "            train_buckets,\n",
        "            shuffle_buckets=True\n",
        "        )\n",
        "\n",
        "        val_loader = create_length_grouped_dataloader(\n",
        "            val_dataset,\n",
        "            config.batch_size,\n",
        "            val_buckets,\n",
        "            shuffle_buckets=False\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        # Use standard data loaders\n",
        "        print(\"\\nüì¶ Creating standard data loaders...\")\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=config.batch_size,\n",
        "            shuffle=True,\n",
        "            collate_fn=collate_fn,\n",
        "            num_workers=0  # Avoid multiprocessing for memory efficiency\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=config.batch_size,\n",
        "            shuffle=False,\n",
        "            collate_fn=collate_fn,\n",
        "            num_workers=0\n",
        "        )\n",
        "\n",
        "    # Initialize model\n",
        "    print(\"\\nü§ñ Initializing model...\")\n",
        "    model = SimplifiedGRUDecoder(config)\n",
        "    print(f\"üìà Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Brain2TextTrainer(model, config)\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\nüöÄ Starting training...\")\n",
        "    training_history = trainer.train(train_loader, val_loader)\n",
        "\n",
        "    # Save training history\n",
        "    history_path = os.path.join(output_dir, 'training_history.json')\n",
        "    with open(history_path, 'w') as f:\n",
        "        json.dump(training_history, f, indent=2)\n",
        "\n",
        "    # Plot training curves\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(training_history['train_losses'], label='Train Loss')\n",
        "    if training_history['val_losses']:\n",
        "        plt.plot(training_history['val_losses'], label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('CTC Loss')\n",
        "    plt.title('Training Progress')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(training_history['train_losses'], label='Train Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('CTC Loss')\n",
        "    plt.title('Training Loss (Log Scale)')\n",
        "    plt.yscale('log')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'training_curves.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Load best model for evaluation\n",
        "    if os.path.exists('best_model.pt'):\n",
        "        model.load_state_dict(torch.load('best_model.pt'))\n",
        "        print(\"üì• Loaded best model for evaluation\")\n",
        "\n",
        "    # Initialize inference\n",
        "    print(\"\\nüîç Starting evaluation...\")\n",
        "    inference = Brain2TextInference(model, config)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_results = inference.evaluate_dataset(val_loader)\n",
        "\n",
        "    # Language model conversion (FULL IMPLEMENTATION)\n",
        "    if skip_full_evaluation:\n",
        "        print(\"\\n‚è≠Ô∏è  Skipping full language model evaluation (skip_full_evaluation=True)\")\n",
        "        print(\"üîÑ Using simple language model for quick results...\")\n",
        "        language_model = SimpleLanguageModel()\n",
        "        # Limit samples for faster evaluation\n",
        "        eval_predictions = val_results['predictions'][:max_eval_samples]\n",
        "        predicted_texts = language_model.phonemes_to_text(eval_predictions)\n",
        "        print(f\"‚úÖ Evaluated {len(predicted_texts)} samples with simple language model\")\n",
        "    else:\n",
        "        print(\"\\nü§ñ Initializing full language model...\")\n",
        "        try:\n",
        "            language_model = FullLanguageModel(use_opt=True, use_fallback=True)\n",
        "            # Limit samples to prevent excessive wait time\n",
        "            eval_predictions = val_results['predictions'][:max_eval_samples]\n",
        "            print(f\"üîÑ Evaluating {len(eval_predictions)} samples (limited from {len(val_results['predictions'])} total)\")\n",
        "            predicted_texts = language_model.phonemes_to_text(eval_predictions)\n",
        "            print(\"‚úÖ Using full language model with OPT-6.7B\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Full language model failed: {e}\")\n",
        "            print(\"üîÑ Falling back to simple language model...\")\n",
        "            language_model = SimpleLanguageModel()\n",
        "            eval_predictions = val_results['predictions'][:max_eval_samples]\n",
        "            predicted_texts = language_model.phonemes_to_text(eval_predictions)\n",
        "\n",
        "    # Calculate WER if transcriptions available\n",
        "    # Get transcriptions for the samples we actually evaluated (first max_eval_samples)\n",
        "    eval_transcriptions = val_results['transcriptions'][:len(predicted_texts)]\n",
        "    valid_transcriptions = [t for t in eval_transcriptions if t is not None and str(t).strip()]\n",
        "\n",
        "    print(f\"\\nüìä Transcription analysis:\")\n",
        "    print(f\"   Total predictions: {len(predicted_texts)}\")\n",
        "    print(f\"   Transcriptions checked: {len(eval_transcriptions)}\")\n",
        "    print(f\"   Valid transcriptions: {len(valid_transcriptions)}\")\n",
        "    if eval_transcriptions:\n",
        "        sample_trans = eval_transcriptions[:3]\n",
        "        print(f\"   Sample transcriptions: {sample_trans}\")\n",
        "\n",
        "    wer = None  # Initialize WER\n",
        "\n",
        "    if valid_transcriptions:\n",
        "        # Filter to only include samples with valid transcriptions\n",
        "        paired_data = [(pred, trans) for pred, trans in zip(predicted_texts, eval_transcriptions)\n",
        "                       if trans is not None and str(trans).strip()]\n",
        "        if paired_data:\n",
        "            paired_predictions, paired_transcriptions = zip(*paired_data)\n",
        "            wer = calculate_wer(list(paired_predictions), list(paired_transcriptions))\n",
        "            print(f\"üìä Word Error Rate (WER): {wer:.3f} ({wer*100:.1f}%)\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  No valid prediction-transcription pairs found for WER calculation\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No valid transcriptions found in the data!\")\n",
        "        print(\"   This usually means transcription/sentence_label fields are missing from HDF5 files\")\n",
        "\n",
        "    # Save results\n",
        "    results = {\n",
        "        'wer': wer,\n",
        "        'phoneme_accuracy': val_results.get('phoneme_accuracy', None),\n",
        "        'num_samples': val_results['num_samples'],\n",
        "        'config': config.__dict__\n",
        "    }\n",
        "\n",
        "    results_path = os.path.join(output_dir, 'evaluation_results.json')\n",
        "    with open(results_path, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    # Save sample predictions\n",
        "    sample_predictions = []\n",
        "    for i in range(min(10, len(predicted_texts))):\n",
        "        sample_predictions.append({\n",
        "            'sample_id': i,\n",
        "            'predicted_phonemes': val_results['predictions'][i],\n",
        "            'predicted_text': predicted_texts[i],\n",
        "            'target_text': eval_transcriptions[i] if i < len(eval_transcriptions) else None\n",
        "        })\n",
        "\n",
        "    samples_path = os.path.join(output_dir, 'sample_predictions.json')\n",
        "    with open(samples_path, 'w') as f:\n",
        "        json.dump(sample_predictions, f, indent=2)\n",
        "\n",
        "    print(f\"\\n‚úÖ Training complete! Results saved to: {output_dir}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Return results including WER if calculated\n",
        "    return_dict = {\n",
        "        'model': model,\n",
        "        'trainer': trainer,\n",
        "        'inference': inference,\n",
        "        'results': val_results\n",
        "    }\n",
        "\n",
        "    # Add WER if it was calculated\n",
        "    if 'wer' in locals():\n",
        "        return_dict['wer'] = wer\n",
        "        print(f\"üìä Final WER: {wer:.3f} ({wer*100:.1f}%)\")\n",
        "\n",
        "    return return_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DEMlrzl9QkD"
      },
      "source": [
        "# SECTION 11: ADVANCED PIPELINE FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7EXLPw9Z83MV"
      },
      "outputs": [],
      "source": [
        "def main_training_pipeline_full_lm(data_dir: str, output_dir: str = \"brain2text_output_full\"):\n",
        "    \"\"\"\n",
        "    Training pipeline with guaranteed full language model integration\n",
        "    Optimized for best performance with OPT-6.7B\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üß† BRAIN-TO-TEXT 2025: FULL LANGUAGE MODEL PIPELINE\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Check memory and provide recommendations\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        print(f\"üîß GPU Memory: {gpu_memory:.1f}GB\")\n",
        "\n",
        "        if gpu_memory < 12:\n",
        "            print(\"‚ö†Ô∏è  WARNING: GPU has <12GB memory. OPT-6.7B may not fit.\")\n",
        "            print(\"üí° RECOMMENDATION: Use Colab Pro or reduce to GPT-2 Medium\")\n",
        "        else:\n",
        "            print(\"‚úÖ GPU memory sufficient for OPT-6.7B\")\n",
        "\n",
        "    # Run standard training pipeline first\n",
        "    results = main_training_pipeline(data_dir, output_dir)\n",
        "\n",
        "    # Override with full language model for final evaluation\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üöÄ FINAL EVALUATION WITH FULL LANGUAGE MODEL\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Force full language model usage\n",
        "    print(\"ü§ñ Loading full language model (OPT-6.7B)...\")\n",
        "    full_language_model = FullLanguageModel(use_opt=True, use_fallback=True)\n",
        "\n",
        "    # Re-evaluate with full language model\n",
        "    inference = results['inference']\n",
        "    val_loader = None  # You'd need to pass this from main_training_pipeline\n",
        "\n",
        "    # For now, use the existing results but with full LM\n",
        "    predicted_texts_full = full_language_model.phonemes_to_text(results['results']['predictions'])\n",
        "\n",
        "    # Calculate final WER\n",
        "    # Get transcriptions matching the number of predictions\n",
        "    all_transcriptions = results['results']['transcriptions'][:len(predicted_texts_full)]\n",
        "    valid_transcriptions = [t for t in all_transcriptions if t is not None and str(t).strip()]\n",
        "\n",
        "    wer_full = None\n",
        "    if valid_transcriptions:\n",
        "        # Filter to only include samples with valid transcriptions\n",
        "        paired_data = [(pred, trans) for pred, trans in zip(predicted_texts_full, all_transcriptions)\n",
        "                       if trans is not None and str(trans).strip()]\n",
        "        if paired_data:\n",
        "            paired_predictions, paired_transcriptions = zip(*paired_data)\n",
        "            wer_full = calculate_wer(list(paired_predictions), list(paired_transcriptions))\n",
        "            print(f\"üìä Final Word Error Rate (WER) with OPT-6.7B: {wer_full:.3f} ({wer_full*100:.1f}%)\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  No valid prediction-transcription pairs found for WER calculation\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No valid transcriptions found for WER calculation\")\n",
        "\n",
        "    # Save full results (always save, even if WER couldn't be calculated)\n",
        "    full_results = {\n",
        "        'wer_full_lm': wer_full,\n",
        "        'predicted_texts_full': predicted_texts_full[:10],  # Save first 10 examples\n",
        "        'model_used': 'OPT-6.7B' if full_language_model.opt_model else 'GPT-2-Medium',\n",
        "        'config': config.__dict__\n",
        "    }\n",
        "\n",
        "    full_results_path = os.path.join(output_dir, 'full_lm_results.json')\n",
        "    with open(full_results_path, 'w') as f:\n",
        "        json.dump(full_results, f, indent=2)\n",
        "\n",
        "    print(f\"üíæ Full LM results saved to: {full_results_path}\")\n",
        "\n",
        "    print(\"‚úÖ Full language model evaluation complete!\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkxeRN6-9jvc"
      },
      "source": [
        "# SECTION 12: UTILITY FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GsGM-r_q9QLo"
      },
      "outputs": [],
      "source": [
        "def download_brain2text_data(data_dir: str = \"/content/brain2text_data\") -> str:\n",
        "    \"\"\"\n",
        "    Download Brain-to-Text 2025 data directly from Dryad repository\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory to save downloaded data\n",
        "\n",
        "    Returns:\n",
        "        Path to downloaded data directory\n",
        "    \"\"\"\n",
        "    import urllib.request\n",
        "    import json\n",
        "    import zipfile\n",
        "    import tempfile\n",
        "    from pathlib import Path\n",
        "\n",
        "    print(\"üåê Downloading Brain-to-Text 2025 data from Dryad...\")\n",
        "    print(\"‚è≥ This may take 10-30 minutes depending on your connection...\")\n",
        "\n",
        "    # Create data directory\n",
        "    data_path = Path(data_dir)\n",
        "    data_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Dryad repository information\n",
        "    DRYAD_DOI = \"10.5061/dryad.dncjsxm85\"\n",
        "    DRYAD_ROOT = \"https://datadryad.org\"\n",
        "    urlified_doi = DRYAD_DOI.replace(\"/\", \"%2F\")\n",
        "\n",
        "    try:\n",
        "        # Get file list from Dryad API\n",
        "        print(\"üìã Fetching file list from Dryad API...\")\n",
        "        versions_url = f\"{DRYAD_ROOT}/api/v2/datasets/doi:{urlified_doi}/versions\"\n",
        "\n",
        "        with urllib.request.urlopen(versions_url) as response:\n",
        "            versions_info = json.loads(response.read().decode())\n",
        "\n",
        "        files_url_path = versions_info[\"_embedded\"][\"stash:versions\"][-1][\"_links\"][\"stash:files\"][\"href\"]\n",
        "        files_url = f\"{DRYAD_ROOT}{files_url_path}\"\n",
        "\n",
        "        with urllib.request.urlopen(files_url) as response:\n",
        "            files_info = json.loads(response.read().decode())\n",
        "\n",
        "        file_infos = files_info[\"_embedded\"][\"stash:files\"]\n",
        "\n",
        "        print(f\"üìÅ Found {len(file_infos)} files to download\")\n",
        "\n",
        "        # Download each file\n",
        "        downloaded_files = []\n",
        "        for i, file_info in enumerate(file_infos):\n",
        "            filename = file_info[\"path\"]\n",
        "            file_size = file_info.get(\"size\", 0)\n",
        "\n",
        "            # Skip README files\n",
        "            if filename.lower() == \"readme.md\":\n",
        "                continue\n",
        "\n",
        "            print(f\"üì• Downloading {filename} ({i+1}/{len(file_infos)}) - {file_size/1e6:.1f}MB...\")\n",
        "\n",
        "            download_path = file_info[\"_links\"][\"stash:download\"][\"href\"]\n",
        "            download_url = f\"{DRYAD_ROOT}{download_path}\"\n",
        "            download_to_filepath = data_path / filename\n",
        "\n",
        "            # Download with progress indication\n",
        "            try:\n",
        "                urllib.request.urlretrieve(download_url, download_to_filepath)\n",
        "                downloaded_files.append(download_to_filepath)\n",
        "\n",
        "                # Extract if it's a zip file\n",
        "                if file_info[\"mimeType\"] == \"application/zip\" or filename.endswith('.zip'):\n",
        "                    print(f\"üì¶ Extracting {filename}...\")\n",
        "                    with zipfile.ZipFile(download_to_filepath, \"r\") as zf:\n",
        "                        zf.extractall(data_path)\n",
        "\n",
        "                    # Remove zip file after extraction to save space\n",
        "                    download_to_filepath.unlink()\n",
        "                    print(f\"üóëÔ∏è  Removed {filename} after extraction\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è  Failed to download {filename}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Verify HDF5 files are present\n",
        "        hdf5_files = list(data_path.rglob(\"*.hdf5\"))\n",
        "        h5_files = list(data_path.rglob(\"*.h5\"))\n",
        "\n",
        "        total_data_files = len(hdf5_files) + len(h5_files)\n",
        "\n",
        "        if total_data_files == 0:\n",
        "            print(\"‚ö†Ô∏è  Warning: No HDF5 files found after download!\")\n",
        "            print(\"üìÅ Directory contents:\")\n",
        "            for item in data_path.iterdir():\n",
        "                print(f\"   {item.name}\")\n",
        "        else:\n",
        "            print(f\"‚úÖ Download complete! Found {total_data_files} data files\")\n",
        "            print(f\"üìä HDF5 files: {len(hdf5_files)}\")\n",
        "            print(f\"üìä H5 files: {len(h5_files)}\")\n",
        "\n",
        "        # Print directory structure\n",
        "        print(f\"\\nüìÅ Data saved to: {data_path}\")\n",
        "        print(\"üìã Directory structure:\")\n",
        "        for item in sorted(data_path.iterdir()):\n",
        "            if item.is_dir():\n",
        "                sub_files = list(item.iterdir())\n",
        "                print(f\"   üìÅ {item.name}/ ({len(sub_files)} files)\")\n",
        "            else:\n",
        "                file_size = item.stat().st_size / 1e6\n",
        "                print(f\"   üìÑ {item.name} ({file_size:.1f}MB)\")\n",
        "\n",
        "        return str(data_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error downloading data: {e}\")\n",
        "        print(\"üí° Alternative: Upload your data manually to the data directory\")\n",
        "        print(f\"üí° Expected location: {data_path}\")\n",
        "        return str(data_path)\n",
        "\n",
        "def verify_data_structure(data_dir: str) -> bool:\n",
        "    \"\"\"\n",
        "    Verify that the downloaded data has the expected structure\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing the data\n",
        "\n",
        "    Returns:\n",
        "        True if data structure is valid\n",
        "    \"\"\"\n",
        "    data_path = Path(data_dir)\n",
        "\n",
        "    print(f\"üîç Verifying data structure in {data_path}...\")\n",
        "\n",
        "    # Look for HDF5 files\n",
        "    hdf5_files = list(data_path.rglob(\"*.hdf5\"))\n",
        "    h5_files = list(data_path.rglob(\"*.h5\"))\n",
        "\n",
        "    total_files = len(hdf5_files) + len(h5_files)\n",
        "\n",
        "    if total_files == 0:\n",
        "        print(\"‚ùå No HDF5 data files found!\")\n",
        "        return False\n",
        "\n",
        "    print(f\"‚úÖ Found {total_files} data files\")\n",
        "\n",
        "    # Try to open one file and check structure\n",
        "    test_file = hdf5_files[0] if hdf5_files else h5_files[0]\n",
        "\n",
        "    try:\n",
        "        with h5py.File(test_file, 'r') as f:\n",
        "            keys = list(f.keys())\n",
        "\n",
        "            if not keys:\n",
        "                print(f\"‚ö†Ô∏è  File {test_file.name} is empty\")\n",
        "                return False\n",
        "\n",
        "            # Check first trial structure\n",
        "            first_trial = f[keys[0]]\n",
        "            expected_keys = ['input_features', 'seq_class_ids', 'transcription']\n",
        "\n",
        "            missing_keys = [key for key in expected_keys if key not in first_trial]\n",
        "\n",
        "            if missing_keys:\n",
        "                print(f\"‚ö†Ô∏è  Missing expected keys in {test_file.name}: {missing_keys}\")\n",
        "                print(f\"üìã Available keys: {list(first_trial.keys())}\")\n",
        "            else:\n",
        "                print(\"‚úÖ Data structure looks correct\")\n",
        "\n",
        "            # Check data shapes\n",
        "            neural_features = first_trial['input_features']\n",
        "            print(f\"üìä Neural features shape: {neural_features.shape}\")\n",
        "            print(f\"üìä Expected: (time_steps, 512)\")\n",
        "\n",
        "            if neural_features.shape[1] != 512:\n",
        "                print(f\"‚ö†Ô∏è  Unexpected feature dimension: {neural_features.shape[1]} (expected 512)\")\n",
        "                return False\n",
        "\n",
        "            return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error reading test file {test_file.name}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Utility function for memory management\n",
        "def analyze_sequence_lengths(dataset):\n",
        "    \"\"\"\n",
        "    Analyze sequence length distribution in the dataset\n",
        "\n",
        "    Args:\n",
        "        dataset: Brain2TextDataset instance or Subset\n",
        "\n",
        "    Returns:\n",
        "        List of sequence lengths\n",
        "    \"\"\"\n",
        "    # Handle both Brain2TextDataset and Subset objects\n",
        "    if hasattr(dataset, 'samples'):\n",
        "        # Direct Brain2TextDataset\n",
        "        samples = dataset.samples\n",
        "    elif hasattr(dataset, 'dataset'):\n",
        "        # Subset object from random_split\n",
        "        samples = [dataset.dataset.samples[i] for i in dataset.indices]\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset type: {type(dataset)}\")\n",
        "\n",
        "    lengths = [sample['n_time_steps'] for sample in samples]\n",
        "\n",
        "    print(f\"üìä Sequence Length Analysis:\")\n",
        "    print(f\"   Total samples: {len(lengths)}\")\n",
        "    print(f\"   Min length: {min(lengths)}\")\n",
        "    print(f\"   Max length: {max(lengths)}\")\n",
        "    print(f\"   Mean length: {np.mean(lengths):.1f}\")\n",
        "    print(f\"   Median length: {np.median(lengths):.1f}\")\n",
        "    print(f\"   Std length: {np.std(lengths):.1f}\")\n",
        "\n",
        "    # Show percentiles\n",
        "    percentiles = [25, 50, 75, 90, 95, 99]\n",
        "    for p in percentiles:\n",
        "        print(f\"   {p}th percentile: {np.percentile(lengths, p):.0f}\")\n",
        "\n",
        "    return lengths\n",
        "\n",
        "def create_length_buckets(dataset, bucket_boundaries=[500, 1000, 1500, 2000, 3000]):\n",
        "    \"\"\"\n",
        "    Group samples into buckets by sequence length\n",
        "\n",
        "    Args:\n",
        "        dataset: Brain2TextDataset instance or Subset\n",
        "        bucket_boundaries: List of length boundaries for bucketing\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping bucket names to sample indices (relative to the dataset)\n",
        "    \"\"\"\n",
        "    buckets = {}\n",
        "\n",
        "    # Handle both Brain2TextDataset and Subset objects\n",
        "    if hasattr(dataset, 'samples'):\n",
        "        # Direct Brain2TextDataset\n",
        "        samples = dataset.samples\n",
        "        sample_indices = list(range(len(samples)))\n",
        "    elif hasattr(dataset, 'dataset'):\n",
        "        # Subset object from random_split\n",
        "        samples = [dataset.dataset.samples[i] for i in dataset.indices]\n",
        "        sample_indices = list(range(len(samples)))  # Use local indices for the subset\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset type: {type(dataset)}\")\n",
        "\n",
        "    # Create bucket names\n",
        "    bucket_names = []\n",
        "    for i in range(len(bucket_boundaries)):\n",
        "        if i == 0:\n",
        "            bucket_names.append(f\"0-{bucket_boundaries[i]}\")\n",
        "        else:\n",
        "            bucket_names.append(f\"{bucket_boundaries[i-1]+1}-{bucket_boundaries[i]}\")\n",
        "    bucket_names.append(f\"{bucket_boundaries[-1]+1}+\")\n",
        "\n",
        "    # Initialize buckets\n",
        "    for name in bucket_names:\n",
        "        buckets[name] = []\n",
        "\n",
        "    # Sort samples into buckets\n",
        "    for idx, sample in enumerate(samples):\n",
        "        length = sample['n_time_steps']\n",
        "\n",
        "        # Find appropriate bucket\n",
        "        bucket_idx = len(bucket_boundaries)  # Default to largest bucket\n",
        "        for i, boundary in enumerate(bucket_boundaries):\n",
        "            if length <= boundary:\n",
        "                bucket_idx = i\n",
        "                break\n",
        "\n",
        "        bucket_name = bucket_names[bucket_idx]\n",
        "        buckets[bucket_name].append(idx)  # Use local index\n",
        "\n",
        "    # Print bucket statistics (sorted by average length, largest first)\n",
        "    print(f\"üìÅ Length-based buckets (largest first):\")\n",
        "    non_empty_buckets = [(name, indices) for name, indices in buckets.items() if indices]\n",
        "\n",
        "    # Sort by bucket name in reverse order (largest first)\n",
        "    non_empty_buckets.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    for name, indices in non_empty_buckets:\n",
        "        sample_lengths = [samples[i]['n_time_steps'] for i in indices]\n",
        "        avg_length = np.mean(sample_lengths)\n",
        "        max_length = max(sample_lengths)\n",
        "        min_length = min(sample_lengths)\n",
        "        print(f\"   {name}: {len(indices)} samples (avg: {avg_length:.0f}, range: {min_length}-{max_length})\")\n",
        "\n",
        "    return buckets\n",
        "\n",
        "class LengthGroupedSampler:\n",
        "    \"\"\"\n",
        "    Sampler that groups by length and processes largest buckets first\n",
        "    \"\"\"\n",
        "    def __init__(self, buckets, batch_size, shuffle_buckets=True, shuffle_within_bucket=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle_buckets = shuffle_buckets\n",
        "        self.shuffle_within_bucket = shuffle_within_bucket\n",
        "\n",
        "        # Filter out empty buckets and sort by size (largest first)\n",
        "        self.bucket_data = []\n",
        "        for bucket_name, indices in buckets.items():\n",
        "            if indices:  # Only non-empty buckets\n",
        "                # Extract average length for sorting\n",
        "                if '+' in bucket_name:\n",
        "                    avg_length = float('inf')  # Largest bucket\n",
        "                elif '-' in bucket_name:\n",
        "                    # Get the upper bound of the range\n",
        "                    avg_length = float(bucket_name.split('-')[1])\n",
        "                else:\n",
        "                    avg_length = 0\n",
        "                self.bucket_data.append((avg_length, bucket_name, indices))\n",
        "\n",
        "        # Sort by average length (largest first)\n",
        "        self.bucket_data.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        print(f\"üîÑ Processing order (largest sequences first):\")\n",
        "        total_batches = 0\n",
        "        for avg_length, bucket_name, indices in self.bucket_data:\n",
        "            num_batches = len(indices) // batch_size\n",
        "            total_batches += num_batches\n",
        "            print(f\"   {bucket_name}: {len(indices)} samples ‚Üí {num_batches} full batches\")\n",
        "\n",
        "        print(f\"üìä Total full batches: {total_batches}\")\n",
        "        self.total_batches = total_batches\n",
        "\n",
        "    def __iter__(self):\n",
        "        all_batches = []\n",
        "\n",
        "        # Process each bucket (largest first)\n",
        "        for avg_length, bucket_name, indices in self.bucket_data:\n",
        "            bucket_indices = indices.copy()\n",
        "\n",
        "            # Shuffle within bucket if requested\n",
        "            if self.shuffle_within_bucket:\n",
        "                import random\n",
        "                random.shuffle(bucket_indices)\n",
        "\n",
        "            # Create batches from this bucket\n",
        "            for i in range(0, len(bucket_indices), self.batch_size):\n",
        "                batch_indices = bucket_indices[i:i + self.batch_size]\n",
        "                if len(batch_indices) == self.batch_size:  # Only full batches\n",
        "                    all_batches.append((avg_length, batch_indices))\n",
        "\n",
        "        # Optionally shuffle the order of batches while preserving size grouping\n",
        "        if self.shuffle_buckets:\n",
        "            import random\n",
        "            random.shuffle(all_batches)\n",
        "\n",
        "        # Yield batch indices\n",
        "        for avg_length, batch_indices in all_batches:\n",
        "            yield batch_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_batches\n",
        "\n",
        "def create_length_grouped_dataloader(dataset, batch_size, buckets, shuffle_buckets=True):\n",
        "    \"\"\"\n",
        "    Create DataLoader with length-based grouping\n",
        "\n",
        "    Args:\n",
        "        dataset: Brain2TextDataset instance or Subset\n",
        "        batch_size: Batch size for training\n",
        "        buckets: Dictionary from create_length_buckets\n",
        "        shuffle_buckets: Whether to shuffle the order of buckets\n",
        "\n",
        "    Returns:\n",
        "        Custom DataLoader with length grouping\n",
        "    \"\"\"\n",
        "    sampler = LengthGroupedSampler(buckets, batch_size, shuffle_buckets=shuffle_buckets)\n",
        "\n",
        "    def length_grouped_collate_fn(batch_indices):\n",
        "        \"\"\"Collate function that works with batch indices\"\"\"\n",
        "        # Handle both Brain2TextDataset and Subset objects\n",
        "        if hasattr(dataset, 'samples'):\n",
        "            # Direct Brain2TextDataset\n",
        "            batch = [dataset.samples[i] for i in batch_indices]\n",
        "        elif hasattr(dataset, 'dataset'):\n",
        "            # Subset object from random_split\n",
        "            batch = [dataset.dataset.samples[dataset.indices[i]] for i in batch_indices]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported dataset type: {type(dataset)}\")\n",
        "\n",
        "        return collate_fn(batch)\n",
        "\n",
        "    class LengthGroupedDataLoader:\n",
        "        \"\"\"Custom DataLoader for length-grouped batches\"\"\"\n",
        "        def __init__(self, dataset, sampler, collate_fn):\n",
        "            self.dataset = dataset\n",
        "            self.sampler = sampler\n",
        "            self.collate_fn = collate_fn\n",
        "\n",
        "        def __iter__(self):\n",
        "            for batch_indices in self.sampler:\n",
        "                yield self.collate_fn(batch_indices)\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.sampler)\n",
        "\n",
        "    return LengthGroupedDataLoader(dataset, sampler, length_grouped_collate_fn)\n",
        "\n",
        "def optimize_for_colab():\n",
        "    \"\"\"\n",
        "    Optimize settings for Google Colab environment\n",
        "    \"\"\"\n",
        "    print(\"üîß Optimizing for Google Colab...\")\n",
        "\n",
        "    # Clear any existing GPU memory\n",
        "    clear_gpu_memory()\n",
        "\n",
        "    # Set memory fraction if needed\n",
        "    if torch.cuda.is_available():\n",
        "        # Allow memory growth\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Print memory info\n",
        "        allocated = torch.cuda.memory_allocated() / 1e9\n",
        "        cached = torch.cuda.memory_reserved() / 1e9\n",
        "        print(f\"üìä GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
        "\n",
        "    # Set environment variables for optimization\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "\n",
        "    print(\"‚úÖ Colab optimization complete!\")\n",
        "\n",
        "# Quick test function\n",
        "def quick_test_language_model():\n",
        "    \"\"\"\n",
        "    Quick test of the language model functionality\n",
        "    \"\"\"\n",
        "    print(\"üß™ Testing language model functionality...\")\n",
        "\n",
        "    # Test phoneme sequences\n",
        "    test_phonemes = [\n",
        "        ['DH', 'AH', 'P', 'EY', 'SH', 'AH', 'N', 'T'],  # \"the patient\"\n",
        "        ['D', 'AA', 'K', 'T', 'ER', 'S', 'EH', 'D'],     # \"doctor said\"\n",
        "        ['IH', 'N', 'DH', 'AH', 'HH', 'AA', 'S', 'P', 'IH', 'T', 'AH', 'L']  # \"in the hospital\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Test full language model\n",
        "        print(\"Testing FullLanguageModel...\")\n",
        "        full_lm = FullLanguageModel(use_opt=False, use_fallback=True)  # Skip OPT for quick test\n",
        "        full_results = full_lm.phonemes_to_text(test_phonemes)\n",
        "\n",
        "        print(\"Full LM Results:\")\n",
        "        for i, (phonemes, text) in enumerate(zip(test_phonemes, full_results)):\n",
        "            print(f\"  {i+1}. {phonemes} ‚Üí '{text}'\")\n",
        "\n",
        "        # Test simple language model\n",
        "        print(\"\\nTesting SimpleLanguageModel...\")\n",
        "        simple_lm = SimpleLanguageModel()\n",
        "        simple_results = simple_lm.phonemes_to_text(test_phonemes)\n",
        "\n",
        "        print(\"Simple LM Results:\")\n",
        "        for i, (phonemes, text) in enumerate(zip(test_phonemes, simple_results)):\n",
        "            print(f\"  {i+1}. {phonemes} ‚Üí '{text}'\")\n",
        "\n",
        "        print(\"‚úÖ Language model test complete!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Language model test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCpInsbk-hrs"
      },
      "source": [
        "# SECTION 13: USAGE EXAMPLES AND INSTRUCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPOZdfzs9QBy",
        "outputId": "b7d188f6-5c2d-4e9d-d185-36a730a2b187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    üß† BRAIN-TO-TEXT 2025: STANDARD TRAINING PIPELINE\n",
            "\n",
            "    This script implements the competition's standard approach with full data download capability:\n",
            "    1. Automated data download from Dryad repository\n",
            "    2. GRU encoder for neural feature processing\n",
            "    3. CTC loss for phoneme prediction\n",
            "    4. Full language model integration (OPT-6.7B + N-gram)\n",
            "    5. Word Error Rate (WER) evaluation\n",
            "\n",
            "    üéØ TWO-STEP EXECUTION PROCESS:\n",
            "\n",
            "    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "    üì• STEP 1: DATA DOWNLOAD AND VERIFICATION\n",
            "    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "\n",
            "    # Install dependencies first\n",
            "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
            "    !pip install transformers accelerate bitsandbytes optimum\n",
            "    !pip install h5py numpy pandas scikit-learn tqdm matplotlib seaborn\n",
            "    !pip install pyctcdecode\n",
            "\n",
            "    # Download and verify data (10-30 minutes)\n",
            "    data_dir = download_brain2text_data(\"/content/brain2text_data\")\n",
            "    data_valid = verify_data_structure(data_dir)\n",
            "\n",
            "    if data_valid:\n",
            "        print(\"‚úÖ Data is ready for training!\")\n",
            "    else:\n",
            "        print(\"‚ùå Data verification failed. Upload manually.\")\n",
            "\n",
            "    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "    üèãÔ∏è STEP 2: TRAINING AND EVALUATION\n",
            "    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "\n",
            "    # 2A: Basic Training with Simple Language Model\n",
            "    optimize_for_colab()\n",
            "    quick_test_language_model()\n",
            "\n",
            "    results_basic = main_training_pipeline(\n",
            "        data_dir=\"/content/brain2text_data\",\n",
            "        output_dir=\"/content/brain2text_results\",\n",
            "        max_epochs=10,\n",
            "        batch_size=32,\n",
            "        use_simple_lm=True\n",
            "    )\n",
            "\n",
            "    # 2B: Advanced Training with Full Language Model (OPT-6.7B)\n",
            "    # ‚ö†Ô∏è  Requires >12GB GPU memory (Colab Pro recommended)\n",
            "    results_full = main_training_pipeline_full_lm(\n",
            "        data_dir=\"/content/brain2text_data\",\n",
            "        output_dir=\"/content/brain2text_results_full\",\n",
            "        max_epochs=10,\n",
            "        batch_size=16  # Smaller batch for memory\n",
            "    )\n",
            "\n",
            "    üöÄ QUICK START (Copy-Paste Ready):\n",
            "\n",
            "    # Complete pipeline in one go\n",
            "    data_dir = download_brain2text_data()\n",
            "    if verify_data_structure(data_dir):\n",
            "        optimize_for_colab()\n",
            "        results = main_training_pipeline(\n",
            "            data_dir=data_dir,\n",
            "            max_epochs=5,\n",
            "            batch_size=16,  # Reduced for memory efficiency\n",
            "            use_length_grouping=True,  # Enable memory optimization\n",
            "            skip_full_evaluation=False,  # Enable full evaluation to get WER\n",
            "            max_eval_samples=100  # Limit evaluation samples for speed\n",
            "        )\n",
            "        print(f\"Training complete! WER: {results.get('wer', 'N/A')}\")\n",
            "\n",
            "        # WER should now be calculated properly using official train/val splits\n",
            "\n",
            "    EXPECTED PERFORMANCE:\n",
            "    - Baseline WER: ~6.7% (competition baseline)\n",
            "    - With Full LM WER: ~5.5% (estimated with OPT-6.7B)\n",
            "    - Target WER: <5% (to beat 2024 winner)\n",
            "    - Data download: ~10-30 minutes\n",
            "    - Training time: ~2-4 hours on Colab GPU\n",
            "    - LM Loading time: ~5-10 minutes (OPT-6.7B download)\n",
            "\n",
            "    KEY CHANGES FOR WER CALCULATION:\n",
            "    - Now uses official train/val splits (not random split)\n",
            "    - Properly extracts sentence_label and transcription from HDF5 files\n",
            "    - WER calculated on validation set with ground truth labels\n",
            "    - Test set used only for final submission (no ground truth available)\n",
            "\n",
            "    MEMORY REQUIREMENTS:\n",
            "    - Training: ~8GB VRAM (GRU model)\n",
            "    - OPT-6.7B: ~12.4GB VRAM (use Colab Pro for best results)\n",
            "    - Total RAM: ~16GB (Colab Pro recommended)\n",
            "\n",
            "    TROUBLESHOOTING:\n",
            "    - Data download fails ‚Üí Use manual upload alternative\n",
            "    - Out of memory ‚Üí Reduce batch_size, use gradient accumulation\n",
            "    - CUDA errors ‚Üí Restart runtime, check GPU availability\n",
            "\n",
            "    SECTION REFERENCE:\n",
            "    - Section 1-3: Setup and configuration\n",
            "    - Section 4-5: Data loading and model architecture\n",
            "    - Section 6-7: Training and inference\n",
            "    - Section 8-9: Language model and evaluation\n",
            "    - Section 10-11: Pipeline functions\n",
            "    - Section 12: Utility functions (Data download, Colab optimization)\n",
            "    - Section 13: This usage guide\n",
            "    \n",
            "üåê Downloading Brain-to-Text 2025 data from Dryad...\n",
            "‚è≥ This may take 10-30 minutes depending on your connection...\n",
            "üìã Fetching file list from Dryad API...\n",
            "üìÅ Found 5 files to download\n",
            "üì• Downloading t15_copyTask_neuralData.zip (2/5) - 11051.0MB...\n",
            "üì¶ Extracting t15_copyTask_neuralData.zip...\n",
            "üóëÔ∏è  Removed t15_copyTask_neuralData.zip after extraction\n",
            "üì• Downloading t15_copyTask.pkl (3/5) - 57.8MB...\n",
            "üì• Downloading t15_personalUse.pkl (4/5) - 1.1MB...\n",
            "üì• Downloading t15_pretrained_rnn_baseline.zip (5/5) - 484.9MB...\n",
            "üì¶ Extracting t15_pretrained_rnn_baseline.zip...\n",
            "üóëÔ∏è  Removed t15_pretrained_rnn_baseline.zip after extraction\n",
            "‚úÖ Download complete! Found 127 data files\n",
            "üìä HDF5 files: 127\n",
            "üìä H5 files: 0\n",
            "\n",
            "üìÅ Data saved to: /content/brain2text_data\n",
            "üìã Directory structure:\n",
            "   üìÅ __MACOSX/ (2 files)\n",
            "   üìÅ hdf5_data_final/ (45 files)\n",
            "   üìÑ t15_copyTask.pkl (57.8MB)\n",
            "   üìÑ t15_personalUse.pkl (1.1MB)\n",
            "   üìÅ t15_pretrained_rnn_baseline/ (3 files)\n",
            "üîç Verifying data structure in /content/brain2text_data...\n",
            "‚úÖ Found 127 data files\n",
            "‚ö†Ô∏è  Missing expected keys in data_test.hdf5: ['seq_class_ids', 'transcription']\n",
            "üìã Available keys: ['input_features']\n",
            "üìä Neural features shape: (598, 512)\n",
            "üìä Expected: (time_steps, 512)\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"\"\"\n",
        "    üß† BRAIN-TO-TEXT 2025: STANDARD TRAINING PIPELINE\n",
        "\n",
        "    This script implements the competition's standard approach with full data download capability:\n",
        "    1. Automated data download from Dryad repository\n",
        "    2. GRU encoder for neural feature processing\n",
        "    3. CTC loss for phoneme prediction\n",
        "    4. Full language model integration (OPT-6.7B + N-gram)\n",
        "    5. Word Error Rate (WER) evaluation\n",
        "\n",
        "    üéØ TWO-STEP EXECUTION PROCESS:\n",
        "\n",
        "    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "    üì• STEP 1: DATA DOWNLOAD AND VERIFICATION\n",
        "    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "    # Install dependencies first\n",
        "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "    !pip install transformers accelerate bitsandbytes optimum\n",
        "    !pip install h5py numpy pandas scikit-learn tqdm matplotlib seaborn\n",
        "    !pip install pyctcdecode\n",
        "\n",
        "    # Download and verify data (10-30 minutes)\n",
        "    data_dir = download_brain2text_data(\"/content/brain2text_data\")\n",
        "    data_valid = verify_data_structure(data_dir)\n",
        "\n",
        "    if data_valid:\n",
        "        print(\"‚úÖ Data is ready for training!\")\n",
        "    else:\n",
        "        print(\"‚ùå Data verification failed. Upload manually.\")\n",
        "\n",
        "    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "    üèãÔ∏è STEP 2: TRAINING AND EVALUATION\n",
        "    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "    # 2A: Basic Training with Simple Language Model\n",
        "    optimize_for_colab()\n",
        "    quick_test_language_model()\n",
        "\n",
        "    results_basic = main_training_pipeline(\n",
        "        data_dir=\"/content/brain2text_data\",\n",
        "        output_dir=\"/content/brain2text_results\",\n",
        "        max_epochs=10,\n",
        "        batch_size=32,\n",
        "        use_simple_lm=True\n",
        "    )\n",
        "\n",
        "    # 2B: Advanced Training with Full Language Model (OPT-6.7B)\n",
        "    # ‚ö†Ô∏è  Requires >12GB GPU memory (Colab Pro recommended)\n",
        "    results_full = main_training_pipeline_full_lm(\n",
        "        data_dir=\"/content/brain2text_data\",\n",
        "        output_dir=\"/content/brain2text_results_full\",\n",
        "        max_epochs=10,\n",
        "        batch_size=16  # Smaller batch for memory\n",
        "    )\n",
        "\n",
        "    üöÄ QUICK START (Copy-Paste Ready):\n",
        "\n",
        "    # Complete pipeline in one go\n",
        "    data_dir = download_brain2text_data()\n",
        "    if verify_data_structure(data_dir):\n",
        "        optimize_for_colab()\n",
        "        results = main_training_pipeline(\n",
        "            data_dir=data_dir,\n",
        "            max_epochs=5,\n",
        "            batch_size=16,  # Reduced for memory efficiency\n",
        "            use_length_grouping=True,  # Enable memory optimization\n",
        "            skip_full_evaluation=False,  # Enable full evaluation to get WER\n",
        "            max_eval_samples=100  # Limit evaluation samples for speed\n",
        "        )\n",
        "        print(f\"Training complete! WER: {results.get('wer', 'N/A')}\")\n",
        "\n",
        "        # WER should now be calculated properly using official train/val splits\n",
        "\n",
        "    EXPECTED PERFORMANCE:\n",
        "    - Baseline WER: ~6.7% (competition baseline)\n",
        "    - With Full LM WER: ~5.5% (estimated with OPT-6.7B)\n",
        "    - Target WER: <5% (to beat 2024 winner)\n",
        "    - Data download: ~10-30 minutes\n",
        "    - Training time: ~2-4 hours on Colab GPU\n",
        "    - LM Loading time: ~5-10 minutes (OPT-6.7B download)\n",
        "\n",
        "    KEY CHANGES FOR WER CALCULATION:\n",
        "    - Now uses official train/val splits (not random split)\n",
        "    - Properly extracts sentence_label and transcription from HDF5 files\n",
        "    - WER calculated on validation set with ground truth labels\n",
        "    - Test set used only for final submission (no ground truth available)\n",
        "\n",
        "    MEMORY REQUIREMENTS:\n",
        "    - Training: ~8GB VRAM (GRU model)\n",
        "    - OPT-6.7B: ~12.4GB VRAM (use Colab Pro for best results)\n",
        "    - Total RAM: ~16GB (Colab Pro recommended)\n",
        "\n",
        "    TROUBLESHOOTING:\n",
        "    - Data download fails ‚Üí Use manual upload alternative\n",
        "    - Out of memory ‚Üí Reduce batch_size, use gradient accumulation\n",
        "    - CUDA errors ‚Üí Restart runtime, check GPU availability\n",
        "\n",
        "    SECTION REFERENCE:\n",
        "    - Section 1-3: Setup and configuration\n",
        "    - Section 4-5: Data loading and model architecture\n",
        "    - Section 6-7: Training and inference\n",
        "    - Section 8-9: Language model and evaluation\n",
        "    - Section 10-11: Pipeline functions\n",
        "    - Section 12: Utility functions (Data download, Colab optimization)\n",
        "    - Section 13: This usage guide\n",
        "    \"\"\")\n",
        "\n",
        "    # Example usage (uncomment to run)\n",
        "    # Step 1: Download data\n",
        "    data_dir = download_brain2text_data(\"/content/brain2text_data\")\n",
        "    data_valid = verify_data_structure(data_dir)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "43f6407989484f40b0da7880268c8c62",
            "5f0d1fac69ca4f8aa4ee50b8c28ffe0f",
            "eb7ffd5b29544c06ac43e8f285e03352",
            "1361f89613e240d1b012faf48966491a",
            "718aa29eb67c467f8f06b57d0bf9b658",
            "5f6168f628804a4a9f3ad9af26ff981a",
            "2e5e1435bbcf45fbac3721c228f69e2a",
            "2b02188f1b6944d4a1f61383c7a85b77",
            "a56f461d5a6b49b6bb8f97e2b55901fb",
            "756198d91b14488981bfe02370e818a6",
            "9bd15d46c72e4223874f667f3704c1d9"
          ]
        },
        "id": "2ezi_3bh_Sa_",
        "outputId": "af025376-442f-4249-a35e-d38b2e6edb33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Optimizing for Google Colab...\n",
            "üìä GPU Memory - Allocated: 13.61GB, Cached: 27.10GB\n",
            "‚úÖ Colab optimization complete!\n",
            "================================================================================\n",
            "üß† BRAIN-TO-TEXT 2025: MEMORY-OPTIMIZED TRAINING PIPELINE\n",
            "================================================================================\n",
            "üîß Configuration:\n",
            "   Batch size: 32\n",
            "   Learning rate: 0.001\n",
            "   Max epochs: 135\n",
            "   Length grouping: True\n",
            "   Bucket boundaries: [500, 1000, 1500, 2000, 3000]\n",
            "   Skip full evaluation: False\n",
            "   Max eval samples: 100\n",
            "\n",
            "üìÅ Loading datasets...\n",
            "üìÅ Found 45 HDF5 files for 'train' split\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_train.hdf5 for train...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "üìù Transcription stats: 8072/8072 samples have transcriptions\n",
            "   Sources: {'sentence_label': 8072, 'transcription': 8072, 'sentenceText': 0, 'none': 0}\n",
            "üìä Loaded 8072 samples for train split\n",
            "üìÅ Found 41 HDF5 files for 'val' split\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "Loading data_val.hdf5 for val...\n",
            "   üìã First trial keys: ['input_features', 'seq_class_ids', 'transcription']\n",
            "   üìã First trial attrs: ['block_num', 'n_time_steps', 'sentence_label', 'seq_len', 'session', 'trial_num']\n",
            "üìù Transcription stats: 1426/1426 samples have transcriptions\n",
            "   Sources: {'sentence_label': 1426, 'transcription': 1426, 'sentenceText': 0, 'none': 0}\n",
            "üìä Loaded 1426 samples for val split\n",
            "üìä Train samples: 8072\n",
            "üìä Val samples: 1426\n",
            "\n",
            "üìè Analyzing sequence lengths...\n",
            "üìä Sequence Length Analysis:\n",
            "   Total samples: 8072\n",
            "   Min length: 138\n",
            "   Max length: 2475\n",
            "   Mean length: 874.8\n",
            "   Median length: 836.0\n",
            "   Std length: 308.3\n",
            "   25th percentile: 655\n",
            "   50th percentile: 836\n",
            "   75th percentile: 1050\n",
            "   90th percentile: 1275\n",
            "   95th percentile: 1426\n",
            "   99th percentile: 1773\n",
            "üìÅ Length-based buckets (largest first):\n",
            "   501-1000: 4966 samples (avg: 759, range: 501-1000)\n",
            "   2001-3000: 37 samples (avg: 2200, range: 2007-2475)\n",
            "   1501-2000: 259 samples (avg: 1659, range: 1501-1999)\n",
            "   1001-1500: 2117 samples (avg: 1178, range: 1001-1500)\n",
            "   0-500: 693 samples (avg: 416, range: 138-500)\n",
            "üìÅ Length-based buckets (largest first):\n",
            "   501-1000: 843 samples (avg: 774, range: 502-999)\n",
            "   2001-3000: 10 samples (avg: 2151, range: 2042-2382)\n",
            "   1501-2000: 65 samples (avg: 1663, range: 1501-1984)\n",
            "   1001-1500: 416 samples (avg: 1185, range: 1001-1495)\n",
            "   0-500: 92 samples (avg: 438, range: 297-500)\n",
            "\n",
            "üîÑ Creating length-grouped data loaders...\n",
            "üîÑ Processing order (largest sequences first):\n",
            "   2001-3000: 37 samples ‚Üí 1 full batches\n",
            "   1501-2000: 259 samples ‚Üí 8 full batches\n",
            "   1001-1500: 2117 samples ‚Üí 66 full batches\n",
            "   501-1000: 4966 samples ‚Üí 155 full batches\n",
            "   0-500: 693 samples ‚Üí 21 full batches\n",
            "üìä Total full batches: 251\n",
            "üîÑ Processing order (largest sequences first):\n",
            "   2001-3000: 10 samples ‚Üí 0 full batches\n",
            "   1501-2000: 65 samples ‚Üí 2 full batches\n",
            "   1001-1500: 416 samples ‚Üí 13 full batches\n",
            "   501-1000: 843 samples ‚Üí 26 full batches\n",
            "   0-500: 92 samples ‚Üí 2 full batches\n",
            "üìä Total full batches: 43\n",
            "\n",
            "ü§ñ Initializing model...\n",
            "üìà Model parameters: 17,163,305\n",
            "\n",
            "üöÄ Starting training...\n",
            "üöÄ Starting training for 135 epochs\n",
            "üìä Model: SimplifiedGRUDecoder(\n",
            "  (input_dropout): Dropout(p=0.2, inplace=False)\n",
            "  (gru): GRU(512, 768, num_layers=5, batch_first=True, dropout=0.4)\n",
            "  (output_projection): Linear(in_features=768, out_features=41, bias=True)\n",
            ")\n",
            "‚öôÔ∏è  Config: Config(neural_dim=512, hidden_size=768, num_layers=5)\n",
            "\n",
            "üìÖ Epoch 1/135\n",
            "  Batch 0/251, Loss: 113.7839\n",
            "  Batch 50/251, Loss: 3.3253\n",
            "  Batch 100/251, Loss: 3.3326\n",
            "  Batch 150/251, Loss: 3.2199\n",
            "  Batch 200/251, Loss: 3.1683\n",
            "  Batch 250/251, Loss: 3.0453\n",
            "üíæ Saved best model (val_loss: 3.0208)\n",
            "üìà Train Loss: 4.3480, Val Loss: 3.0208, LR: 0.001000\n",
            "\n",
            "üìÖ Epoch 2/135\n",
            "  Batch 0/251, Loss: 3.0253\n",
            "  Batch 50/251, Loss: 2.7278\n",
            "  Batch 100/251, Loss: 2.5892\n",
            "  Batch 150/251, Loss: 2.4369\n",
            "  Batch 200/251, Loss: 3.2337\n",
            "  Batch 250/251, Loss: 3.1684\n",
            "üìà Train Loss: 2.7758, Val Loss: 3.1837, LR: 0.000999\n",
            "\n",
            "üìÖ Epoch 3/135\n",
            "  Batch 0/251, Loss: 3.3073\n",
            "  Batch 50/251, Loss: 2.8967\n",
            "  Batch 100/251, Loss: 2.4965\n",
            "  Batch 150/251, Loss: 2.2276\n",
            "  Batch 200/251, Loss: 2.1903\n",
            "  Batch 250/251, Loss: 2.2218\n",
            "üíæ Saved best model (val_loss: 2.1724)\n",
            "üìà Train Loss: 2.5092, Val Loss: 2.1724, LR: 0.000999\n",
            "\n",
            "üìÖ Epoch 4/135\n",
            "  Batch 0/251, Loss: 2.1306\n",
            "  Batch 50/251, Loss: 1.7922\n",
            "  Batch 100/251, Loss: 2.0781\n",
            "  Batch 150/251, Loss: 1.8046\n",
            "  Batch 200/251, Loss: 2.0107\n",
            "  Batch 250/251, Loss: 1.8052\n",
            "üíæ Saved best model (val_loss: 1.9504)\n",
            "üìà Train Loss: 2.0451, Val Loss: 1.9504, LR: 0.000998\n",
            "\n",
            "üìÖ Epoch 5/135\n",
            "  Batch 0/251, Loss: 1.6252\n",
            "  Batch 50/251, Loss: 2.0214\n",
            "  Batch 100/251, Loss: 1.8764\n",
            "  Batch 150/251, Loss: 1.8140\n",
            "  Batch 200/251, Loss: 1.7656\n",
            "  Batch 250/251, Loss: 1.6788\n",
            "üíæ Saved best model (val_loss: 1.8581)\n",
            "üìà Train Loss: 1.8638, Val Loss: 1.8581, LR: 0.000997\n",
            "\n",
            "üìÖ Epoch 6/135\n",
            "  Batch 0/251, Loss: 1.8103\n",
            "  Batch 50/251, Loss: 1.8578\n",
            "  Batch 100/251, Loss: 1.8640\n",
            "  Batch 150/251, Loss: 1.8868\n",
            "  Batch 200/251, Loss: 1.8607\n",
            "  Batch 250/251, Loss: 1.5927\n",
            "üíæ Saved best model (val_loss: 1.8420)\n",
            "üìà Train Loss: 1.7297, Val Loss: 1.8420, LR: 0.000995\n",
            "\n",
            "üìÖ Epoch 7/135\n",
            "  Batch 0/251, Loss: 1.5665\n",
            "  Batch 50/251, Loss: 1.6155\n",
            "  Batch 100/251, Loss: 1.5433\n",
            "  Batch 150/251, Loss: 1.5940\n",
            "  Batch 200/251, Loss: 1.5812\n",
            "  Batch 250/251, Loss: 1.6576\n",
            "üíæ Saved best model (val_loss: 1.7781)\n",
            "üìà Train Loss: 1.6453, Val Loss: 1.7781, LR: 0.000993\n",
            "\n",
            "üìÖ Epoch 8/135\n",
            "  Batch 0/251, Loss: 1.6564\n",
            "  Batch 50/251, Loss: 1.6798\n",
            "  Batch 100/251, Loss: 1.7378\n",
            "  Batch 150/251, Loss: 2.0289\n",
            "  Batch 200/251, Loss: 1.6324\n",
            "  Batch 250/251, Loss: 1.7276\n",
            "üìà Train Loss: 1.6858, Val Loss: 1.7978, LR: 0.000991\n",
            "\n",
            "üìÖ Epoch 9/135\n",
            "  Batch 0/251, Loss: 1.4709\n",
            "  Batch 50/251, Loss: 1.6190\n",
            "  Batch 100/251, Loss: 1.5758\n",
            "  Batch 150/251, Loss: 2.5314\n",
            "  Batch 200/251, Loss: 1.9111\n",
            "  Batch 250/251, Loss: 1.4285\n",
            "üíæ Saved best model (val_loss: 1.7334)\n",
            "üìà Train Loss: 1.6900, Val Loss: 1.7334, LR: 0.000989\n",
            "\n",
            "üìÖ Epoch 10/135\n",
            "  Batch 0/251, Loss: 1.7068\n",
            "  Batch 50/251, Loss: 1.3764\n",
            "  Batch 100/251, Loss: 1.8760\n",
            "  Batch 150/251, Loss: 1.7246\n",
            "  Batch 200/251, Loss: 1.3712\n",
            "  Batch 250/251, Loss: 1.5791\n",
            "üíæ Saved best model (val_loss: 1.6860)\n",
            "üìà Train Loss: 1.5815, Val Loss: 1.6860, LR: 0.000987\n",
            "\n",
            "üìÖ Epoch 11/135\n",
            "  Batch 0/251, Loss: 1.5642\n",
            "  Batch 50/251, Loss: 1.5260\n",
            "  Batch 100/251, Loss: 1.3616\n",
            "  Batch 150/251, Loss: 1.5443\n",
            "  Batch 200/251, Loss: 1.6934\n",
            "  Batch 250/251, Loss: 1.7190\n",
            "üíæ Saved best model (val_loss: 1.6815)\n",
            "üìà Train Loss: 1.5222, Val Loss: 1.6815, LR: 0.000984\n",
            "\n",
            "üìÖ Epoch 12/135\n",
            "  Batch 0/251, Loss: 1.4464\n",
            "  Batch 50/251, Loss: 1.4541\n",
            "  Batch 100/251, Loss: 1.5428\n",
            "  Batch 150/251, Loss: 1.5821\n",
            "  Batch 200/251, Loss: 1.4222\n",
            "  Batch 250/251, Loss: 1.4104\n",
            "üìà Train Loss: 1.4780, Val Loss: 1.7282, LR: 0.000981\n",
            "\n",
            "üìÖ Epoch 13/135\n",
            "  Batch 0/251, Loss: 1.4039\n",
            "  Batch 50/251, Loss: 1.3755\n",
            "  Batch 100/251, Loss: 1.3748\n",
            "  Batch 150/251, Loss: 1.5160\n",
            "  Batch 200/251, Loss: 1.3872\n",
            "  Batch 250/251, Loss: 1.6737\n",
            "üíæ Saved best model (val_loss: 1.6255)\n",
            "üìà Train Loss: 1.4459, Val Loss: 1.6255, LR: 0.000977\n",
            "\n",
            "üìÖ Epoch 14/135\n",
            "  Batch 0/251, Loss: 1.2690\n",
            "  Batch 50/251, Loss: 1.3728\n",
            "  Batch 100/251, Loss: 1.6118\n",
            "  Batch 150/251, Loss: 1.4582\n",
            "  Batch 200/251, Loss: 1.4587\n",
            "  Batch 250/251, Loss: 1.4826\n",
            "üíæ Saved best model (val_loss: 1.6240)\n",
            "üìà Train Loss: 1.4469, Val Loss: 1.6240, LR: 0.000974\n",
            "\n",
            "üìÖ Epoch 15/135\n",
            "  Batch 0/251, Loss: 1.5153\n",
            "  Batch 50/251, Loss: 1.6933\n",
            "  Batch 100/251, Loss: 1.2996\n",
            "  Batch 150/251, Loss: 1.3158\n",
            "  Batch 200/251, Loss: 1.4477\n",
            "  Batch 250/251, Loss: 1.3605\n",
            "üíæ Saved best model (val_loss: 1.6093)\n",
            "üìà Train Loss: 1.4198, Val Loss: 1.6093, LR: 0.000970\n",
            "\n",
            "üìÖ Epoch 16/135\n",
            "  Batch 0/251, Loss: 1.2518\n",
            "  Batch 50/251, Loss: 1.5269\n",
            "  Batch 100/251, Loss: 1.6133\n",
            "  Batch 150/251, Loss: 1.7115\n",
            "  Batch 200/251, Loss: 1.4641\n",
            "  Batch 250/251, Loss: 1.4161\n",
            "üìà Train Loss: 1.4256, Val Loss: 1.6855, LR: 0.000966\n",
            "\n",
            "üìÖ Epoch 17/135\n",
            "  Batch 0/251, Loss: 1.5230\n",
            "  Batch 50/251, Loss: 1.6882\n",
            "  Batch 100/251, Loss: 1.3785\n",
            "  Batch 150/251, Loss: 1.3685\n",
            "  Batch 200/251, Loss: 1.5499\n",
            "  Batch 250/251, Loss: 1.4032\n",
            "üìà Train Loss: 1.4368, Val Loss: 1.6182, LR: 0.000961\n",
            "\n",
            "üìÖ Epoch 18/135\n",
            "  Batch 0/251, Loss: 1.6895\n",
            "  Batch 50/251, Loss: 1.3645\n",
            "  Batch 100/251, Loss: 1.3627\n",
            "  Batch 150/251, Loss: 1.3989\n",
            "  Batch 200/251, Loss: 1.5031\n",
            "  Batch 250/251, Loss: 1.2487\n",
            "üíæ Saved best model (val_loss: 1.5850)\n",
            "üìà Train Loss: 1.4042, Val Loss: 1.5850, LR: 0.000957\n",
            "\n",
            "üìÖ Epoch 19/135\n",
            "  Batch 0/251, Loss: 1.1999\n",
            "  Batch 50/251, Loss: 1.3420\n",
            "  Batch 100/251, Loss: 1.6006\n",
            "  Batch 150/251, Loss: 1.4822\n",
            "  Batch 200/251, Loss: 1.3904\n",
            "  Batch 250/251, Loss: 1.3772\n",
            "üìà Train Loss: 1.3862, Val Loss: 1.5890, LR: 0.000952\n",
            "\n",
            "üìÖ Epoch 20/135\n",
            "  Batch 0/251, Loss: 1.1410\n",
            "  Batch 50/251, Loss: 1.4195\n",
            "  Batch 100/251, Loss: 1.0879\n",
            "  Batch 150/251, Loss: 1.3811\n",
            "  Batch 200/251, Loss: 1.3965\n",
            "  Batch 250/251, Loss: 1.4709\n",
            "üìà Train Loss: 1.3991, Val Loss: 1.6582, LR: 0.000947\n",
            "\n",
            "üìÖ Epoch 21/135\n",
            "  Batch 0/251, Loss: 1.4403\n",
            "  Batch 50/251, Loss: 1.5012\n",
            "  Batch 100/251, Loss: 1.4781\n",
            "  Batch 150/251, Loss: 1.3585\n",
            "  Batch 200/251, Loss: 1.3041\n",
            "  Batch 250/251, Loss: 1.3393\n",
            "üìà Train Loss: 1.4248, Val Loss: 1.7308, LR: 0.000941\n",
            "\n",
            "üìÖ Epoch 22/135\n",
            "  Batch 0/251, Loss: 1.3290\n",
            "  Batch 50/251, Loss: 1.4020\n",
            "  Batch 100/251, Loss: 1.4791\n",
            "  Batch 150/251, Loss: 1.4461\n",
            "  Batch 200/251, Loss: 1.3366\n",
            "  Batch 250/251, Loss: 1.6425\n",
            "üìà Train Loss: 1.3733, Val Loss: 1.5997, LR: 0.000936\n",
            "\n",
            "üìÖ Epoch 23/135\n",
            "  Batch 0/251, Loss: 1.2814\n",
            "  Batch 50/251, Loss: 1.1990\n",
            "  Batch 100/251, Loss: 1.6088\n",
            "  Batch 150/251, Loss: 1.4376\n",
            "  Batch 200/251, Loss: 1.5422\n",
            "  Batch 250/251, Loss: 1.3954\n",
            "üíæ Saved best model (val_loss: 1.5492)\n",
            "üìà Train Loss: 1.3687, Val Loss: 1.5492, LR: 0.000930\n",
            "\n",
            "üìÖ Epoch 24/135\n",
            "  Batch 0/251, Loss: 1.2371\n",
            "  Batch 50/251, Loss: 1.2558\n",
            "  Batch 100/251, Loss: 1.4998\n",
            "  Batch 150/251, Loss: 1.2536\n",
            "  Batch 200/251, Loss: 1.3252\n",
            "  Batch 250/251, Loss: 1.4585\n",
            "üìà Train Loss: 1.3734, Val Loss: 1.6872, LR: 0.000924\n",
            "\n",
            "üìÖ Epoch 25/135\n",
            "  Batch 0/251, Loss: 1.4688\n",
            "  Batch 50/251, Loss: 1.7099\n",
            "  Batch 100/251, Loss: 1.1997\n",
            "  Batch 150/251, Loss: 1.5646\n",
            "  Batch 200/251, Loss: 1.3084\n",
            "  Batch 250/251, Loss: 1.2560\n",
            "üìà Train Loss: 1.3871, Val Loss: 1.5816, LR: 0.000918\n",
            "\n",
            "üìÖ Epoch 26/135\n",
            "  Batch 0/251, Loss: 1.4251\n",
            "  Batch 50/251, Loss: 1.4375\n",
            "  Batch 100/251, Loss: 1.3058\n",
            "  Batch 150/251, Loss: 1.4064\n",
            "  Batch 200/251, Loss: 1.2368\n",
            "  Batch 250/251, Loss: 1.2127\n",
            "üìà Train Loss: 1.4158, Val Loss: 1.7754, LR: 0.000911\n",
            "\n",
            "üìÖ Epoch 27/135\n",
            "  Batch 0/251, Loss: 1.3953\n",
            "  Batch 50/251, Loss: 1.5955\n",
            "  Batch 100/251, Loss: 1.5011\n",
            "  Batch 150/251, Loss: 1.4208\n",
            "  Batch 200/251, Loss: 1.7626\n",
            "  Batch 250/251, Loss: 1.4464\n",
            "üìà Train Loss: 1.4206, Val Loss: 1.6363, LR: 0.000905\n",
            "\n",
            "üìÖ Epoch 28/135\n",
            "  Batch 0/251, Loss: 1.2383\n",
            "  Batch 50/251, Loss: 1.3950\n",
            "  Batch 100/251, Loss: 1.1800\n",
            "  Batch 150/251, Loss: 1.2941\n",
            "  Batch 200/251, Loss: 1.3343\n",
            "  Batch 250/251, Loss: 1.3401\n",
            "üìà Train Loss: 1.3782, Val Loss: 1.5864, LR: 0.000898\n",
            "\n",
            "üìÖ Epoch 29/135\n",
            "  Batch 0/251, Loss: 1.2999\n",
            "  Batch 50/251, Loss: 1.2452\n",
            "  Batch 100/251, Loss: 1.4329\n",
            "  Batch 150/251, Loss: 1.3524\n",
            "  Batch 200/251, Loss: 1.4483\n",
            "  Batch 250/251, Loss: 1.3928\n",
            "üìà Train Loss: 1.3363, Val Loss: 1.6651, LR: 0.000890\n",
            "\n",
            "üìÖ Epoch 30/135\n",
            "  Batch 0/251, Loss: 1.5067\n",
            "  Batch 50/251, Loss: 1.2366\n",
            "  Batch 100/251, Loss: 1.2905\n",
            "  Batch 150/251, Loss: 1.4369\n",
            "  Batch 200/251, Loss: 1.2407\n",
            "  Batch 250/251, Loss: 1.4020\n",
            "üìà Train Loss: 1.3685, Val Loss: 1.5695, LR: 0.000883\n",
            "\n",
            "üìÖ Epoch 31/135\n",
            "  Batch 0/251, Loss: 1.4773\n",
            "  Batch 50/251, Loss: 1.4265\n",
            "  Batch 100/251, Loss: 1.1339\n",
            "  Batch 150/251, Loss: 1.2782\n",
            "  Batch 200/251, Loss: 1.4077\n",
            "  Batch 250/251, Loss: 1.5678\n",
            "üìà Train Loss: 1.3477, Val Loss: 1.6180, LR: 0.000875\n",
            "\n",
            "üìÖ Epoch 32/135\n",
            "  Batch 0/251, Loss: 1.5394\n",
            "  Batch 50/251, Loss: 1.2964\n",
            "  Batch 100/251, Loss: 1.3938\n",
            "  Batch 150/251, Loss: 1.4123\n",
            "  Batch 200/251, Loss: 1.3930\n",
            "  Batch 250/251, Loss: 1.7254\n",
            "üìà Train Loss: 1.4135, Val Loss: 2.1810, LR: 0.000868\n",
            "\n",
            "üìÖ Epoch 33/135\n",
            "  Batch 0/251, Loss: 1.5854\n",
            "  Batch 50/251, Loss: 1.9817\n",
            "  Batch 100/251, Loss: 2.0835\n",
            "  Batch 150/251, Loss: 1.4783\n",
            "  Batch 200/251, Loss: 1.6220\n",
            "  Batch 250/251, Loss: 1.2279\n",
            "üìà Train Loss: 1.6738, Val Loss: 1.6615, LR: 0.000860\n",
            "\n",
            "üìÖ Epoch 34/135\n",
            "  Batch 0/251, Loss: 1.4926\n",
            "  Batch 50/251, Loss: 1.6273\n",
            "  Batch 100/251, Loss: 1.3576\n",
            "  Batch 150/251, Loss: 1.3147\n",
            "  Batch 200/251, Loss: 1.3486\n",
            "  Batch 250/251, Loss: 1.3118\n",
            "üíæ Saved best model (val_loss: 1.5492)\n",
            "üìà Train Loss: 1.3552, Val Loss: 1.5492, LR: 0.000851\n",
            "\n",
            "üìÖ Epoch 35/135\n",
            "  Batch 0/251, Loss: 1.1044\n",
            "  Batch 50/251, Loss: 1.3629\n",
            "  Batch 100/251, Loss: 1.2147\n",
            "  Batch 150/251, Loss: 1.3043\n",
            "  Batch 200/251, Loss: 1.3882\n",
            "  Batch 250/251, Loss: 1.3447\n",
            "üìà Train Loss: 1.2933, Val Loss: 1.5654, LR: 0.000843\n",
            "\n",
            "üìÖ Epoch 36/135\n",
            "  Batch 0/251, Loss: 1.3582\n",
            "  Batch 50/251, Loss: 1.3040\n",
            "  Batch 100/251, Loss: 1.1820\n",
            "  Batch 150/251, Loss: 1.1040\n",
            "  Batch 200/251, Loss: 1.2280\n",
            "  Batch 250/251, Loss: 1.1710\n",
            "üìà Train Loss: 1.2852, Val Loss: 1.5789, LR: 0.000835\n",
            "\n",
            "üìÖ Epoch 37/135\n",
            "  Batch 0/251, Loss: 1.0742\n",
            "  Batch 50/251, Loss: 1.1738\n",
            "  Batch 100/251, Loss: 1.3953\n",
            "  Batch 150/251, Loss: 1.2774\n",
            "  Batch 200/251, Loss: 1.2470\n",
            "  Batch 250/251, Loss: 1.6562\n",
            "üìà Train Loss: 1.2895, Val Loss: 1.5607, LR: 0.000826\n",
            "\n",
            "üìÖ Epoch 38/135\n",
            "  Batch 0/251, Loss: 1.1875\n",
            "  Batch 50/251, Loss: 1.4349\n",
            "  Batch 100/251, Loss: 1.1711\n",
            "  Batch 150/251, Loss: 1.3424\n",
            "  Batch 200/251, Loss: 1.2972\n",
            "  Batch 250/251, Loss: 1.5270\n",
            "üìà Train Loss: 1.2720, Val Loss: 1.5724, LR: 0.000817\n",
            "\n",
            "üìÖ Epoch 39/135\n",
            "  Batch 0/251, Loss: 1.2036\n",
            "  Batch 50/251, Loss: 1.2452\n",
            "  Batch 100/251, Loss: 1.1826\n",
            "  Batch 150/251, Loss: 1.4763\n",
            "  Batch 200/251, Loss: 1.3086\n",
            "  Batch 250/251, Loss: 1.5195\n",
            "üìà Train Loss: 1.3041, Val Loss: 1.7067, LR: 0.000808\n",
            "\n",
            "üìÖ Epoch 40/135\n",
            "  Batch 0/251, Loss: 1.4872\n",
            "  Batch 50/251, Loss: 1.2860\n",
            "  Batch 100/251, Loss: 1.4923\n",
            "  Batch 150/251, Loss: 1.3021\n",
            "  Batch 200/251, Loss: 1.1349\n",
            "  Batch 250/251, Loss: 1.3956\n",
            "üìà Train Loss: 1.3126, Val Loss: 1.6578, LR: 0.000799\n",
            "\n",
            "üìÖ Epoch 41/135\n",
            "  Batch 0/251, Loss: 1.4224\n",
            "  Batch 50/251, Loss: 1.1304\n",
            "  Batch 100/251, Loss: 1.5189\n",
            "  Batch 150/251, Loss: 1.4281\n",
            "  Batch 200/251, Loss: 1.3020\n",
            "  Batch 250/251, Loss: 1.3551\n",
            "üìà Train Loss: 1.2860, Val Loss: 1.6159, LR: 0.000789\n",
            "\n",
            "üìÖ Epoch 42/135\n",
            "  Batch 0/251, Loss: 1.2525\n",
            "  Batch 50/251, Loss: 1.2724\n",
            "  Batch 100/251, Loss: 1.2617\n",
            "  Batch 150/251, Loss: 1.4774\n",
            "  Batch 200/251, Loss: 1.0850\n",
            "  Batch 250/251, Loss: 1.3474\n",
            "üìà Train Loss: 1.2735, Val Loss: 1.6173, LR: 0.000780\n",
            "\n",
            "üìÖ Epoch 43/135\n",
            "  Batch 0/251, Loss: 1.2039\n",
            "  Batch 50/251, Loss: 1.1563\n",
            "  Batch 100/251, Loss: 1.3417\n",
            "  Batch 150/251, Loss: 1.1454\n",
            "  Batch 200/251, Loss: 1.2302\n",
            "  Batch 250/251, Loss: 1.2401\n",
            "üìà Train Loss: 1.2435, Val Loss: 1.5799, LR: 0.000770\n",
            "\n",
            "üìÖ Epoch 44/135\n",
            "  Batch 0/251, Loss: 1.0795\n",
            "  Batch 50/251, Loss: 1.5058\n",
            "  Batch 100/251, Loss: 1.1905\n",
            "  Batch 150/251, Loss: 1.2558\n",
            "  Batch 200/251, Loss: 1.1975\n",
            "  Batch 250/251, Loss: 1.3984\n",
            "üíæ Saved best model (val_loss: 1.5481)\n",
            "üìà Train Loss: 1.2608, Val Loss: 1.5481, LR: 0.000760\n",
            "\n",
            "üìÖ Epoch 45/135\n",
            "  Batch 0/251, Loss: 1.2074\n",
            "  Batch 50/251, Loss: 1.1777\n",
            "  Batch 100/251, Loss: 1.2924\n",
            "  Batch 150/251, Loss: 1.2283\n",
            "  Batch 200/251, Loss: 1.2600\n",
            "  Batch 250/251, Loss: 1.2260\n",
            "üíæ Saved best model (val_loss: 1.5044)\n",
            "üìà Train Loss: 1.2389, Val Loss: 1.5044, LR: 0.000750\n",
            "\n",
            "üìÖ Epoch 46/135\n",
            "  Batch 0/251, Loss: 1.1173\n",
            "  Batch 50/251, Loss: 1.1210\n",
            "  Batch 100/251, Loss: 1.2551\n",
            "  Batch 150/251, Loss: 1.3551\n",
            "  Batch 200/251, Loss: 1.2100\n",
            "  Batch 250/251, Loss: 1.1274\n",
            "üìà Train Loss: 1.2396, Val Loss: 1.5447, LR: 0.000740\n",
            "\n",
            "üìÖ Epoch 47/135\n",
            "  Batch 0/251, Loss: 1.3128\n",
            "  Batch 50/251, Loss: 1.4625\n",
            "  Batch 100/251, Loss: 1.0825\n",
            "  Batch 150/251, Loss: 1.2265\n",
            "  Batch 200/251, Loss: 1.4161\n",
            "  Batch 250/251, Loss: 1.1379\n",
            "üìà Train Loss: 1.2276, Val Loss: 1.5373, LR: 0.000730\n",
            "\n",
            "üìÖ Epoch 48/135\n",
            "  Batch 0/251, Loss: 1.3028\n",
            "  Batch 50/251, Loss: 1.0556\n",
            "  Batch 100/251, Loss: 1.1490\n",
            "  Batch 150/251, Loss: 1.2108\n",
            "  Batch 200/251, Loss: 1.2137\n",
            "  Batch 250/251, Loss: 1.1925\n",
            "üìà Train Loss: 1.2310, Val Loss: 1.5274, LR: 0.000719\n",
            "\n",
            "üìÖ Epoch 49/135\n",
            "  Batch 0/251, Loss: 1.0239\n",
            "  Batch 50/251, Loss: 1.1193\n",
            "  Batch 100/251, Loss: 1.1449\n",
            "  Batch 150/251, Loss: 1.2897\n",
            "  Batch 200/251, Loss: 1.0962\n",
            "  Batch 250/251, Loss: 1.3570\n",
            "üìà Train Loss: 1.2429, Val Loss: 1.5404, LR: 0.000709\n",
            "\n",
            "üìÖ Epoch 50/135\n",
            "  Batch 0/251, Loss: 0.9823\n",
            "  Batch 50/251, Loss: 1.1523\n",
            "  Batch 100/251, Loss: 1.1320\n",
            "  Batch 150/251, Loss: 1.3946\n",
            "  Batch 200/251, Loss: 1.2970\n",
            "  Batch 250/251, Loss: 1.3788\n",
            "üìà Train Loss: 1.2513, Val Loss: 1.5508, LR: 0.000698\n",
            "\n",
            "üìÖ Epoch 51/135\n",
            "  Batch 0/251, Loss: 1.3554\n",
            "  Batch 50/251, Loss: 1.2359\n",
            "  Batch 100/251, Loss: 1.1331\n",
            "  Batch 150/251, Loss: 1.2057\n",
            "  Batch 200/251, Loss: 1.2166\n",
            "  Batch 250/251, Loss: 1.1880\n",
            "üìà Train Loss: 1.2682, Val Loss: 1.5712, LR: 0.000687\n",
            "\n",
            "üìÖ Epoch 52/135\n",
            "  Batch 0/251, Loss: 1.1978\n",
            "  Batch 50/251, Loss: 1.1959\n",
            "  Batch 100/251, Loss: 1.2987\n",
            "  Batch 150/251, Loss: 0.9966\n",
            "  Batch 200/251, Loss: 1.3383\n",
            "  Batch 250/251, Loss: 1.2929\n",
            "üìà Train Loss: 1.2645, Val Loss: 1.5700, LR: 0.000676\n",
            "\n",
            "üìÖ Epoch 53/135\n",
            "  Batch 0/251, Loss: 1.3048\n",
            "  Batch 50/251, Loss: 1.0613\n",
            "  Batch 100/251, Loss: 1.0321\n",
            "  Batch 150/251, Loss: 1.2375\n",
            "  Batch 200/251, Loss: 1.1458\n",
            "  Batch 250/251, Loss: 1.1943\n",
            "üìà Train Loss: 1.2591, Val Loss: 1.5703, LR: 0.000666\n",
            "\n",
            "üìÖ Epoch 54/135\n",
            "  Batch 0/251, Loss: 1.2033\n",
            "  Batch 50/251, Loss: 1.1648\n",
            "  Batch 100/251, Loss: 1.3959\n",
            "  Batch 150/251, Loss: 1.2830\n",
            "  Batch 200/251, Loss: 1.3243\n",
            "  Batch 250/251, Loss: 1.2915\n",
            "üìà Train Loss: 1.2325, Val Loss: 1.5620, LR: 0.000655\n",
            "\n",
            "üìÖ Epoch 55/135\n",
            "  Batch 0/251, Loss: 1.1835\n",
            "  Batch 50/251, Loss: 1.1380\n",
            "  Batch 100/251, Loss: 1.2003\n",
            "  Batch 150/251, Loss: 1.1864\n",
            "  Batch 200/251, Loss: 1.3757\n",
            "  Batch 250/251, Loss: 1.4724\n",
            "üìà Train Loss: 1.2370, Val Loss: 1.7124, LR: 0.000643\n",
            "\n",
            "üìÖ Epoch 56/135\n",
            "  Batch 0/251, Loss: 1.4108\n",
            "  Batch 50/251, Loss: 1.8406\n",
            "  Batch 100/251, Loss: 1.2401\n",
            "  Batch 150/251, Loss: 1.2787\n",
            "  Batch 200/251, Loss: 1.1603\n",
            "  Batch 250/251, Loss: 1.1273\n",
            "üìà Train Loss: 1.3479, Val Loss: 1.5522, LR: 0.000632\n",
            "\n",
            "üìÖ Epoch 57/135\n",
            "  Batch 0/251, Loss: 1.1603\n",
            "  Batch 50/251, Loss: 1.2346\n",
            "  Batch 100/251, Loss: 1.2564\n",
            "  Batch 150/251, Loss: 1.0871\n",
            "  Batch 200/251, Loss: 1.2202\n",
            "  Batch 250/251, Loss: 1.3374\n",
            "üìà Train Loss: 1.2443, Val Loss: 1.5486, LR: 0.000621\n",
            "\n",
            "üìÖ Epoch 58/135\n",
            "  Batch 0/251, Loss: 1.1481\n",
            "  Batch 50/251, Loss: 1.1718\n",
            "  Batch 100/251, Loss: 1.4139\n",
            "  Batch 150/251, Loss: 1.2074\n",
            "  Batch 200/251, Loss: 1.1491\n",
            "  Batch 250/251, Loss: 1.4266\n",
            "üìà Train Loss: 1.2173, Val Loss: 1.5255, LR: 0.000610\n",
            "\n",
            "üìÖ Epoch 59/135\n",
            "  Batch 0/251, Loss: 1.1272\n",
            "  Batch 50/251, Loss: 1.2307\n",
            "  Batch 100/251, Loss: 0.9958\n",
            "  Batch 150/251, Loss: 1.2456\n",
            "  Batch 200/251, Loss: 1.1057\n",
            "  Batch 250/251, Loss: 1.1792\n",
            "üìà Train Loss: 1.1965, Val Loss: 1.5217, LR: 0.000598\n",
            "\n",
            "üìÖ Epoch 60/135\n",
            "  Batch 0/251, Loss: 1.1544\n",
            "  Batch 50/251, Loss: 1.2110\n",
            "  Batch 100/251, Loss: 1.1852\n",
            "  Batch 150/251, Loss: 1.2534\n",
            "  Batch 200/251, Loss: 1.0791\n",
            "  Batch 250/251, Loss: 1.1577\n",
            "üìà Train Loss: 1.1946, Val Loss: 1.5240, LR: 0.000587\n",
            "\n",
            "üìÖ Epoch 61/135\n",
            "  Batch 0/251, Loss: 1.1007\n",
            "  Batch 50/251, Loss: 1.0757\n",
            "  Batch 100/251, Loss: 1.1933\n",
            "  Batch 150/251, Loss: 1.2248\n",
            "  Batch 200/251, Loss: 1.1435\n",
            "  Batch 250/251, Loss: 1.1394\n",
            "üìà Train Loss: 1.1843, Val Loss: 1.5602, LR: 0.000575\n",
            "\n",
            "üìÖ Epoch 62/135\n",
            "  Batch 0/251, Loss: 1.2109\n",
            "  Batch 50/251, Loss: 1.1335\n",
            "  Batch 100/251, Loss: 1.3600\n",
            "  Batch 150/251, Loss: 1.0588\n",
            "  Batch 200/251, Loss: 1.1142\n",
            "  Batch 250/251, Loss: 1.0261\n",
            "üìà Train Loss: 1.1962, Val Loss: 1.5432, LR: 0.000564\n",
            "\n",
            "üìÖ Epoch 63/135\n",
            "  Batch 0/251, Loss: 1.2187\n",
            "  Batch 50/251, Loss: 1.3256\n",
            "  Batch 100/251, Loss: 1.0229\n",
            "  Batch 150/251, Loss: 1.1271\n",
            "  Batch 200/251, Loss: 1.2551\n",
            "  Batch 250/251, Loss: 1.2989\n",
            "üìà Train Loss: 1.1828, Val Loss: 1.5342, LR: 0.000552\n",
            "\n",
            "üìÖ Epoch 64/135\n",
            "  Batch 0/251, Loss: 1.1016\n",
            "  Batch 50/251, Loss: 1.2391\n",
            "  Batch 100/251, Loss: 1.2958\n",
            "  Batch 150/251, Loss: 1.4425\n",
            "  Batch 200/251, Loss: 1.2223\n",
            "  Batch 250/251, Loss: 1.4396\n",
            "üìà Train Loss: 1.1866, Val Loss: 1.5252, LR: 0.000541\n",
            "\n",
            "üìÖ Epoch 65/135\n",
            "  Batch 0/251, Loss: 1.1132\n",
            "  Batch 50/251, Loss: 1.0667\n",
            "  Batch 100/251, Loss: 1.0417\n",
            "  Batch 150/251, Loss: 1.2676\n",
            "  Batch 200/251, Loss: 1.3007\n",
            "  Batch 250/251, Loss: 1.1608\n",
            "üìà Train Loss: 1.1743, Val Loss: 1.5335, LR: 0.000529\n",
            "\n",
            "üìÖ Epoch 66/135\n",
            "  Batch 0/251, Loss: 1.3791\n",
            "  Batch 50/251, Loss: 1.2012\n",
            "  Batch 100/251, Loss: 1.2377\n",
            "  Batch 150/251, Loss: 1.1099\n",
            "  Batch 200/251, Loss: 1.4421\n",
            "  Batch 250/251, Loss: 1.1187\n",
            "üíæ Saved best model (val_loss: 1.4922)\n",
            "üìà Train Loss: 1.1681, Val Loss: 1.4922, LR: 0.000517\n",
            "\n",
            "üìÖ Epoch 67/135\n",
            "  Batch 0/251, Loss: 1.3073\n",
            "  Batch 50/251, Loss: 0.9185\n",
            "  Batch 100/251, Loss: 1.2554\n",
            "  Batch 150/251, Loss: 1.2306\n",
            "  Batch 200/251, Loss: 1.2051\n",
            "  Batch 250/251, Loss: 1.2501\n",
            "üíæ Saved best model (val_loss: 1.4886)\n",
            "üìà Train Loss: 1.1834, Val Loss: 1.4886, LR: 0.000506\n",
            "\n",
            "üìÖ Epoch 68/135\n",
            "  Batch 0/251, Loss: 1.1897\n",
            "  Batch 50/251, Loss: 1.0558\n",
            "  Batch 100/251, Loss: 1.3030\n",
            "  Batch 150/251, Loss: 1.4480\n",
            "  Batch 200/251, Loss: 1.4144\n",
            "  Batch 250/251, Loss: 1.1260\n",
            "üìà Train Loss: 1.1802, Val Loss: 1.5051, LR: 0.000494\n",
            "\n",
            "üìÖ Epoch 69/135\n",
            "  Batch 0/251, Loss: 1.4856\n",
            "  Batch 50/251, Loss: 1.0501\n",
            "  Batch 100/251, Loss: 1.2857\n",
            "  Batch 150/251, Loss: 1.1031\n",
            "  Batch 200/251, Loss: 1.1004\n",
            "  Batch 250/251, Loss: 1.2006\n",
            "üìà Train Loss: 1.1656, Val Loss: 1.5502, LR: 0.000483\n",
            "\n",
            "üìÖ Epoch 70/135\n",
            "  Batch 0/251, Loss: 1.1139\n",
            "  Batch 50/251, Loss: 1.0821\n",
            "  Batch 100/251, Loss: 1.0871\n",
            "  Batch 150/251, Loss: 1.1263\n",
            "  Batch 200/251, Loss: 1.2414\n",
            "  Batch 250/251, Loss: 1.4023\n",
            "üìà Train Loss: 1.1706, Val Loss: 1.5524, LR: 0.000471\n",
            "\n",
            "üìÖ Epoch 71/135\n",
            "  Batch 0/251, Loss: 1.2465\n",
            "  Batch 50/251, Loss: 1.2017\n",
            "  Batch 100/251, Loss: 1.2227\n",
            "  Batch 150/251, Loss: 1.2533\n",
            "  Batch 200/251, Loss: 1.1943\n",
            "  Batch 250/251, Loss: 1.0478\n",
            "üìà Train Loss: 1.1561, Val Loss: 1.4897, LR: 0.000459\n",
            "\n",
            "üìÖ Epoch 72/135\n",
            "  Batch 0/251, Loss: 1.2075\n",
            "  Batch 50/251, Loss: 1.2457\n",
            "  Batch 100/251, Loss: 1.1667\n",
            "  Batch 150/251, Loss: 0.9918\n",
            "  Batch 200/251, Loss: 1.0960\n",
            "  Batch 250/251, Loss: 1.1088\n",
            "üíæ Saved best model (val_loss: 1.4885)\n",
            "üìà Train Loss: 1.1629, Val Loss: 1.4885, LR: 0.000448\n",
            "\n",
            "üìÖ Epoch 73/135\n",
            "  Batch 0/251, Loss: 1.0561\n",
            "  Batch 50/251, Loss: 0.9267\n",
            "  Batch 100/251, Loss: 1.0010\n",
            "  Batch 150/251, Loss: 1.0838\n",
            "  Batch 200/251, Loss: 1.1790\n",
            "  Batch 250/251, Loss: 1.2684\n",
            "üìà Train Loss: 1.1497, Val Loss: 1.5228, LR: 0.000436\n",
            "\n",
            "üìÖ Epoch 74/135\n",
            "  Batch 0/251, Loss: 1.1258\n",
            "  Batch 50/251, Loss: 1.1290\n",
            "  Batch 100/251, Loss: 1.0207\n",
            "  Batch 150/251, Loss: 1.1868\n",
            "  Batch 200/251, Loss: 1.2124\n",
            "  Batch 250/251, Loss: 1.1873\n",
            "üìà Train Loss: 1.1759, Val Loss: 1.6374, LR: 0.000425\n",
            "\n",
            "üìÖ Epoch 75/135\n",
            "  Batch 0/251, Loss: 1.0148\n",
            "  Batch 50/251, Loss: 1.2151\n",
            "  Batch 100/251, Loss: 1.1669\n",
            "  Batch 150/251, Loss: 1.3978\n",
            "  Batch 200/251, Loss: 1.1399\n",
            "  Batch 250/251, Loss: 1.0971\n",
            "üìà Train Loss: 1.1791, Val Loss: 1.5557, LR: 0.000413\n",
            "\n",
            "üìÖ Epoch 76/135\n",
            "  Batch 0/251, Loss: 1.0393\n",
            "  Batch 50/251, Loss: 1.0736\n",
            "  Batch 100/251, Loss: 1.0472\n",
            "  Batch 150/251, Loss: 1.0900\n",
            "  Batch 200/251, Loss: 0.9902\n",
            "  Batch 250/251, Loss: 1.0970\n",
            "üìà Train Loss: 1.1515, Val Loss: 1.5512, LR: 0.000402\n",
            "\n",
            "üìÖ Epoch 77/135\n",
            "  Batch 0/251, Loss: 1.0892\n",
            "  Batch 50/251, Loss: 1.0331\n",
            "  Batch 100/251, Loss: 1.0127\n",
            "  Batch 150/251, Loss: 0.9998\n",
            "  Batch 200/251, Loss: 1.1288\n",
            "  Batch 250/251, Loss: 1.0432\n",
            "üìà Train Loss: 1.1477, Val Loss: 1.5161, LR: 0.000390\n",
            "\n",
            "üìÖ Epoch 78/135\n",
            "  Batch 0/251, Loss: 1.3738\n",
            "  Batch 50/251, Loss: 1.3496\n",
            "  Batch 100/251, Loss: 1.3736\n",
            "  Batch 150/251, Loss: 1.3136\n",
            "  Batch 200/251, Loss: 1.1337\n",
            "  Batch 250/251, Loss: 1.1299\n",
            "üìà Train Loss: 1.1454, Val Loss: 1.5271, LR: 0.000379\n",
            "\n",
            "üìÖ Epoch 79/135\n",
            "  Batch 0/251, Loss: 1.1246\n",
            "  Batch 50/251, Loss: 1.0759\n",
            "  Batch 100/251, Loss: 1.1808\n",
            "  Batch 150/251, Loss: 0.9704\n",
            "  Batch 200/251, Loss: 1.1114\n",
            "  Batch 250/251, Loss: 1.2087\n",
            "üìà Train Loss: 1.1406, Val Loss: 1.4987, LR: 0.000368\n",
            "\n",
            "üìÖ Epoch 80/135\n",
            "  Batch 0/251, Loss: 1.1248\n",
            "  Batch 50/251, Loss: 1.1734\n",
            "  Batch 100/251, Loss: 1.0509\n",
            "  Batch 150/251, Loss: 1.2415\n",
            "  Batch 200/251, Loss: 1.0163\n",
            "  Batch 250/251, Loss: 1.0783\n",
            "üìà Train Loss: 1.1214, Val Loss: 1.4931, LR: 0.000357\n",
            "\n",
            "üìÖ Epoch 81/135\n",
            "  Batch 0/251, Loss: 1.0726\n",
            "  Batch 50/251, Loss: 1.1056\n",
            "  Batch 100/251, Loss: 1.0843\n",
            "  Batch 150/251, Loss: 1.0455\n",
            "  Batch 200/251, Loss: 0.8958\n",
            "  Batch 250/251, Loss: 1.0106\n",
            "üíæ Saved best model (val_loss: 1.4869)\n",
            "üìà Train Loss: 1.1311, Val Loss: 1.4869, LR: 0.000345\n",
            "\n",
            "üìÖ Epoch 82/135\n",
            "  Batch 0/251, Loss: 0.9930\n",
            "  Batch 50/251, Loss: 0.9539\n",
            "  Batch 100/251, Loss: 1.0240\n",
            "  Batch 150/251, Loss: 1.1846\n",
            "  Batch 200/251, Loss: 1.0575\n",
            "  Batch 250/251, Loss: 1.1353\n",
            "üìà Train Loss: 1.1168, Val Loss: 1.5170, LR: 0.000334\n",
            "\n",
            "üìÖ Epoch 83/135\n",
            "  Batch 0/251, Loss: 1.0597\n",
            "  Batch 50/251, Loss: 1.2095\n",
            "  Batch 100/251, Loss: 1.2152\n",
            "  Batch 150/251, Loss: 1.1317\n",
            "  Batch 200/251, Loss: 1.1628\n",
            "  Batch 250/251, Loss: 0.9786\n",
            "üìà Train Loss: 1.1275, Val Loss: 1.5836, LR: 0.000324\n",
            "\n",
            "üìÖ Epoch 84/135\n",
            "  Batch 0/251, Loss: 1.3457\n",
            "  Batch 50/251, Loss: 1.1171\n",
            "  Batch 100/251, Loss: 1.0860\n",
            "  Batch 150/251, Loss: 0.8375\n",
            "  Batch 200/251, Loss: 0.9597\n",
            "  Batch 250/251, Loss: 1.2819\n",
            "üìà Train Loss: 1.1263, Val Loss: 1.5142, LR: 0.000313\n",
            "\n",
            "üìÖ Epoch 85/135\n",
            "  Batch 0/251, Loss: 1.1179\n",
            "  Batch 50/251, Loss: 1.0047\n",
            "  Batch 100/251, Loss: 1.1737\n",
            "  Batch 150/251, Loss: 1.0927\n",
            "  Batch 200/251, Loss: 0.9793\n",
            "  Batch 250/251, Loss: 1.0705\n",
            "üíæ Saved best model (val_loss: 1.4620)\n",
            "üìà Train Loss: 1.1105, Val Loss: 1.4620, LR: 0.000302\n",
            "\n",
            "üìÖ Epoch 86/135\n",
            "  Batch 0/251, Loss: 0.9740\n",
            "  Batch 50/251, Loss: 1.0729\n",
            "  Batch 100/251, Loss: 1.0644\n",
            "  Batch 150/251, Loss: 0.8929\n",
            "  Batch 200/251, Loss: 1.2603\n",
            "  Batch 250/251, Loss: 1.2277\n",
            "üìà Train Loss: 1.0953, Val Loss: 1.5510, LR: 0.000291\n",
            "\n",
            "üìÖ Epoch 87/135\n",
            "  Batch 0/251, Loss: 1.1593\n",
            "  Batch 50/251, Loss: 1.1050\n",
            "  Batch 100/251, Loss: 0.9719\n",
            "  Batch 150/251, Loss: 1.0975\n",
            "  Batch 200/251, Loss: 0.8209\n",
            "  Batch 250/251, Loss: 1.1453\n",
            "üìà Train Loss: 1.1019, Val Loss: 1.4774, LR: 0.000281\n",
            "\n",
            "üìÖ Epoch 88/135\n",
            "  Batch 0/251, Loss: 1.0547\n",
            "  Batch 50/251, Loss: 1.1631\n",
            "  Batch 100/251, Loss: 1.1864\n",
            "  Batch 150/251, Loss: 1.0897\n",
            "  Batch 200/251, Loss: 1.1244\n",
            "  Batch 250/251, Loss: 0.9883\n",
            "üìà Train Loss: 1.0938, Val Loss: 1.5244, LR: 0.000270\n",
            "\n",
            "üìÖ Epoch 89/135\n",
            "  Batch 0/251, Loss: 1.2648\n",
            "  Batch 50/251, Loss: 0.9667\n",
            "  Batch 100/251, Loss: 1.1124\n",
            "  Batch 150/251, Loss: 0.9118\n",
            "  Batch 200/251, Loss: 1.1595\n",
            "  Batch 250/251, Loss: 1.1157\n",
            "üìà Train Loss: 1.1051, Val Loss: 1.5767, LR: 0.000260\n",
            "\n",
            "üìÖ Epoch 90/135\n",
            "  Batch 0/251, Loss: 1.0493\n",
            "  Batch 50/251, Loss: 1.2684\n",
            "  Batch 100/251, Loss: 1.2674\n",
            "  Batch 150/251, Loss: 1.1401\n",
            "  Batch 200/251, Loss: 1.1132\n",
            "  Batch 250/251, Loss: 1.3122\n",
            "üìà Train Loss: 1.1405, Val Loss: 1.6770, LR: 0.000250\n",
            "\n",
            "üìÖ Epoch 91/135\n",
            "  Batch 0/251, Loss: 1.2966\n",
            "  Batch 50/251, Loss: 1.0799\n",
            "  Batch 100/251, Loss: 1.2819\n",
            "  Batch 150/251, Loss: 1.1828\n",
            "  Batch 200/251, Loss: 1.1547\n",
            "  Batch 250/251, Loss: 1.0113\n",
            "üìà Train Loss: 1.1330, Val Loss: 1.5373, LR: 0.000240\n",
            "\n",
            "üìÖ Epoch 92/135\n",
            "  Batch 0/251, Loss: 0.8519\n",
            "  Batch 50/251, Loss: 1.1923\n",
            "  Batch 100/251, Loss: 1.1775\n",
            "  Batch 150/251, Loss: 1.4190\n",
            "  Batch 200/251, Loss: 1.0545\n",
            "  Batch 250/251, Loss: 1.0851\n",
            "üìà Train Loss: 1.0986, Val Loss: 1.4911, LR: 0.000230\n",
            "\n",
            "üìÖ Epoch 93/135\n",
            "  Batch 0/251, Loss: 1.0624\n",
            "  Batch 50/251, Loss: 1.0711\n",
            "  Batch 100/251, Loss: 1.1611\n",
            "  Batch 150/251, Loss: 1.2384\n",
            "  Batch 200/251, Loss: 1.1553\n",
            "  Batch 250/251, Loss: 1.0656\n",
            "üìà Train Loss: 1.0854, Val Loss: 1.5242, LR: 0.000220\n",
            "\n",
            "üìÖ Epoch 94/135\n",
            "  Batch 0/251, Loss: 1.1284\n",
            "  Batch 50/251, Loss: 1.0124\n",
            "  Batch 100/251, Loss: 1.3543\n",
            "  Batch 150/251, Loss: 0.8260\n",
            "  Batch 200/251, Loss: 0.9852\n",
            "  Batch 250/251, Loss: 1.2376\n",
            "üìà Train Loss: 1.0837, Val Loss: 1.5691, LR: 0.000211\n",
            "\n",
            "üìÖ Epoch 95/135\n",
            "  Batch 0/251, Loss: 1.0415\n",
            "  Batch 50/251, Loss: 0.8320\n",
            "  Batch 100/251, Loss: 1.1287\n",
            "  Batch 150/251, Loss: 0.9645\n",
            "  Batch 200/251, Loss: 1.0149\n",
            "  Batch 250/251, Loss: 1.1228\n",
            "üìà Train Loss: 1.1177, Val Loss: 1.5729, LR: 0.000201\n",
            "\n",
            "üìÖ Epoch 96/135\n",
            "  Batch 0/251, Loss: 1.1746\n",
            "  Batch 50/251, Loss: 1.1755\n",
            "  Batch 100/251, Loss: 1.2144\n",
            "  Batch 150/251, Loss: 1.2093\n",
            "  Batch 200/251, Loss: 1.2647\n",
            "  Batch 250/251, Loss: 1.1704\n",
            "üìà Train Loss: 1.1815, Val Loss: 1.7337, LR: 0.000192\n",
            "\n",
            "üìÖ Epoch 97/135\n",
            "  Batch 0/251, Loss: 1.3328\n",
            "  Batch 50/251, Loss: 1.1773\n",
            "  Batch 100/251, Loss: 1.4310\n",
            "  Batch 150/251, Loss: 1.2211\n",
            "  Batch 200/251, Loss: 1.3073\n",
            "  Batch 250/251, Loss: 1.2452\n",
            "üìà Train Loss: 1.3036, Val Loss: 1.8190, LR: 0.000183\n",
            "\n",
            "üìÖ Epoch 98/135\n",
            "  Batch 0/251, Loss: 1.3404\n",
            "  Batch 50/251, Loss: 1.2775\n",
            "  Batch 100/251, Loss: 1.4381\n",
            "  Batch 150/251, Loss: 1.2396\n",
            "  Batch 200/251, Loss: 1.4062\n",
            "  Batch 250/251, Loss: 1.3360\n",
            "üìà Train Loss: 1.3720, Val Loss: 1.7917, LR: 0.000174\n",
            "\n",
            "üìÖ Epoch 99/135\n",
            "  Batch 0/251, Loss: 1.3198\n",
            "  Batch 50/251, Loss: 1.1124\n",
            "  Batch 100/251, Loss: 1.3827\n",
            "  Batch 150/251, Loss: 1.2888\n",
            "  Batch 200/251, Loss: 1.0244\n",
            "  Batch 250/251, Loss: 1.1159\n",
            "üìà Train Loss: 1.2239, Val Loss: 1.5764, LR: 0.000165\n",
            "\n",
            "üìÖ Epoch 100/135\n",
            "  Batch 0/251, Loss: 1.0749\n",
            "  Batch 50/251, Loss: 1.0941\n",
            "  Batch 100/251, Loss: 0.8819\n",
            "  Batch 150/251, Loss: 1.1159\n",
            "  Batch 200/251, Loss: 1.2474\n",
            "  Batch 250/251, Loss: 1.0830\n",
            "üìà Train Loss: 1.1549, Val Loss: 1.5463, LR: 0.000157\n",
            "\n",
            "üìÖ Epoch 101/135\n",
            "  Batch 0/251, Loss: 1.0125\n",
            "  Batch 50/251, Loss: 1.1492\n",
            "  Batch 100/251, Loss: 0.9616\n",
            "  Batch 150/251, Loss: 1.0639\n",
            "  Batch 200/251, Loss: 1.2642\n",
            "  Batch 250/251, Loss: 1.1674\n",
            "üìà Train Loss: 1.0847, Val Loss: 1.5182, LR: 0.000149\n",
            "\n",
            "üìÖ Epoch 102/135\n",
            "  Batch 0/251, Loss: 1.1077\n",
            "  Batch 50/251, Loss: 1.0410\n",
            "  Batch 100/251, Loss: 1.0657\n",
            "  Batch 150/251, Loss: 1.1573\n",
            "  Batch 200/251, Loss: 1.0505\n",
            "  Batch 250/251, Loss: 0.9586\n",
            "üìà Train Loss: 1.0617, Val Loss: 1.4776, LR: 0.000140\n",
            "\n",
            "üìÖ Epoch 103/135\n",
            "  Batch 0/251, Loss: 1.0499\n",
            "  Batch 50/251, Loss: 1.0475\n",
            "  Batch 100/251, Loss: 1.1384\n",
            "  Batch 150/251, Loss: 0.9796\n",
            "  Batch 200/251, Loss: 1.1402\n",
            "  Batch 250/251, Loss: 0.8431\n",
            "üìà Train Loss: 1.0548, Val Loss: 1.4926, LR: 0.000132\n",
            "\n",
            "üìÖ Epoch 104/135\n",
            "  Batch 0/251, Loss: 0.8497\n",
            "  Batch 50/251, Loss: 1.3143\n",
            "  Batch 100/251, Loss: 1.1189\n",
            "  Batch 150/251, Loss: 1.1178\n",
            "  Batch 200/251, Loss: 1.1155\n",
            "  Batch 250/251, Loss: 1.0477\n",
            "üìà Train Loss: 1.0587, Val Loss: 1.5407, LR: 0.000125\n",
            "\n",
            "üìÖ Epoch 105/135\n",
            "  Batch 0/251, Loss: 0.9970\n",
            "  Batch 50/251, Loss: 0.9626\n",
            "  Batch 100/251, Loss: 1.1423\n",
            "  Batch 150/251, Loss: 1.1212\n",
            "  Batch 200/251, Loss: 1.0622\n",
            "  Batch 250/251, Loss: 1.1395\n",
            "üìà Train Loss: 1.0664, Val Loss: 1.5146, LR: 0.000117\n",
            "\n",
            "üìÖ Epoch 106/135\n",
            "  Batch 0/251, Loss: 1.0913\n",
            "  Batch 50/251, Loss: 1.1578\n",
            "  Batch 100/251, Loss: 1.0317\n",
            "  Batch 150/251, Loss: 0.8587\n",
            "  Batch 200/251, Loss: 0.9712\n",
            "  Batch 250/251, Loss: 0.9984\n",
            "üìà Train Loss: 1.0399, Val Loss: 1.4735, LR: 0.000110\n",
            "\n",
            "üìÖ Epoch 107/135\n",
            "  Batch 0/251, Loss: 1.0131\n",
            "  Batch 50/251, Loss: 1.1097\n",
            "  Batch 100/251, Loss: 1.0696\n",
            "  Batch 150/251, Loss: 1.0308\n",
            "  Batch 200/251, Loss: 0.9881\n",
            "  Batch 250/251, Loss: 0.9614\n",
            "üìà Train Loss: 1.0331, Val Loss: 1.4695, LR: 0.000102\n",
            "\n",
            "üìÖ Epoch 108/135\n",
            "  Batch 0/251, Loss: 0.9358\n",
            "  Batch 50/251, Loss: 0.9916\n",
            "  Batch 100/251, Loss: 0.8993\n",
            "  Batch 150/251, Loss: 0.9761\n",
            "  Batch 200/251, Loss: 1.0282\n",
            "  Batch 250/251, Loss: 1.0274\n",
            "üíæ Saved best model (val_loss: 1.4426)\n",
            "üìà Train Loss: 1.0186, Val Loss: 1.4426, LR: 0.000095\n",
            "\n",
            "üìÖ Epoch 109/135\n",
            "  Batch 0/251, Loss: 1.1425\n",
            "  Batch 50/251, Loss: 1.0706\n",
            "  Batch 100/251, Loss: 0.8234\n",
            "  Batch 150/251, Loss: 1.0533\n",
            "  Batch 200/251, Loss: 1.1453\n",
            "  Batch 250/251, Loss: 0.9387\n",
            "üíæ Saved best model (val_loss: 1.4262)\n",
            "üìà Train Loss: 1.0135, Val Loss: 1.4262, LR: 0.000089\n",
            "\n",
            "üìÖ Epoch 110/135\n",
            "  Batch 0/251, Loss: 1.0750\n",
            "  Batch 50/251, Loss: 0.8670\n",
            "  Batch 100/251, Loss: 0.9808\n",
            "  Batch 150/251, Loss: 0.9698\n",
            "  Batch 200/251, Loss: 1.2510\n",
            "  Batch 250/251, Loss: 0.8912\n",
            "üìà Train Loss: 1.0132, Val Loss: 1.4467, LR: 0.000082\n",
            "\n",
            "üìÖ Epoch 111/135\n",
            "  Batch 0/251, Loss: 1.0257\n",
            "  Batch 50/251, Loss: 0.9799\n",
            "  Batch 100/251, Loss: 0.8947\n",
            "  Batch 150/251, Loss: 0.9327\n",
            "  Batch 200/251, Loss: 1.0233\n",
            "  Batch 250/251, Loss: 0.9579\n",
            "üìà Train Loss: 1.0090, Val Loss: 1.4318, LR: 0.000076\n",
            "\n",
            "üìÖ Epoch 112/135\n",
            "  Batch 0/251, Loss: 0.8788\n",
            "  Batch 50/251, Loss: 0.9858\n",
            "  Batch 100/251, Loss: 1.0138\n",
            "  Batch 150/251, Loss: 1.0545\n",
            "  Batch 200/251, Loss: 0.9437\n",
            "  Batch 250/251, Loss: 1.0912\n",
            "üíæ Saved best model (val_loss: 1.4247)\n",
            "üìà Train Loss: 1.0058, Val Loss: 1.4247, LR: 0.000070\n",
            "\n",
            "üìÖ Epoch 113/135\n",
            "  Batch 0/251, Loss: 0.9919\n",
            "  Batch 50/251, Loss: 1.2095\n",
            "  Batch 100/251, Loss: 1.0151\n",
            "  Batch 150/251, Loss: 1.0837\n",
            "  Batch 200/251, Loss: 1.0011\n",
            "  Batch 250/251, Loss: 1.0604\n",
            "üìà Train Loss: 1.0013, Val Loss: 1.4392, LR: 0.000064\n",
            "\n",
            "üìÖ Epoch 114/135\n",
            "  Batch 0/251, Loss: 1.0214\n",
            "  Batch 50/251, Loss: 0.8997\n",
            "  Batch 100/251, Loss: 1.0004\n",
            "  Batch 150/251, Loss: 1.0522\n",
            "  Batch 200/251, Loss: 0.8852\n",
            "  Batch 250/251, Loss: 0.9915\n",
            "üìà Train Loss: 0.9993, Val Loss: 1.4376, LR: 0.000059\n",
            "\n",
            "üìÖ Epoch 115/135\n",
            "  Batch 0/251, Loss: 0.9963\n",
            "  Batch 50/251, Loss: 1.0773\n",
            "  Batch 100/251, Loss: 0.9173\n",
            "  Batch 150/251, Loss: 0.9917\n",
            "  Batch 200/251, Loss: 1.0469\n",
            "  Batch 250/251, Loss: 1.1572\n",
            "üìà Train Loss: 0.9956, Val Loss: 1.4307, LR: 0.000053\n",
            "\n",
            "üìÖ Epoch 116/135\n",
            "  Batch 0/251, Loss: 0.9929\n",
            "  Batch 50/251, Loss: 1.0562\n",
            "  Batch 100/251, Loss: 0.8561\n",
            "  Batch 150/251, Loss: 0.8462\n",
            "  Batch 200/251, Loss: 0.9929\n",
            "  Batch 250/251, Loss: 0.8482\n",
            "üìà Train Loss: 0.9908, Val Loss: 1.4329, LR: 0.000048\n",
            "\n",
            "üìÖ Epoch 117/135\n",
            "  Batch 0/251, Loss: 0.8984\n",
            "  Batch 50/251, Loss: 0.9606\n",
            "  Batch 100/251, Loss: 1.1230\n",
            "  Batch 150/251, Loss: 0.9927\n",
            "  Batch 200/251, Loss: 0.9774\n",
            "  Batch 250/251, Loss: 1.0397\n",
            "üìà Train Loss: 0.9877, Val Loss: 1.4331, LR: 0.000043\n",
            "\n",
            "üìÖ Epoch 118/135\n",
            "  Batch 0/251, Loss: 1.1271\n",
            "  Batch 50/251, Loss: 1.1937\n",
            "  Batch 100/251, Loss: 1.1311\n",
            "  Batch 150/251, Loss: 1.1288\n",
            "  Batch 200/251, Loss: 1.0964\n",
            "  Batch 250/251, Loss: 1.1306\n",
            "üíæ Saved best model (val_loss: 1.4242)\n",
            "üìà Train Loss: 0.9866, Val Loss: 1.4242, LR: 0.000039\n",
            "\n",
            "üìÖ Epoch 119/135\n",
            "  Batch 0/251, Loss: 1.2707\n",
            "  Batch 50/251, Loss: 0.9567\n",
            "  Batch 100/251, Loss: 0.7870\n",
            "  Batch 150/251, Loss: 0.8873\n",
            "  Batch 200/251, Loss: 0.9616\n",
            "  Batch 250/251, Loss: 1.0704\n",
            "üìà Train Loss: 0.9855, Val Loss: 1.4297, LR: 0.000034\n",
            "\n",
            "üìÖ Epoch 120/135\n",
            "  Batch 0/251, Loss: 0.9878\n",
            "  Batch 50/251, Loss: 0.9243\n",
            "  Batch 100/251, Loss: 1.0903\n",
            "  Batch 150/251, Loss: 1.0251\n",
            "  Batch 200/251, Loss: 0.8801\n",
            "  Batch 250/251, Loss: 1.1321\n",
            "üìà Train Loss: 0.9839, Val Loss: 1.4324, LR: 0.000030\n",
            "\n",
            "üìÖ Epoch 121/135\n",
            "  Batch 0/251, Loss: 1.1476\n",
            "  Batch 50/251, Loss: 0.8771\n",
            "  Batch 100/251, Loss: 1.0436\n",
            "  Batch 150/251, Loss: 1.1467\n",
            "  Batch 200/251, Loss: 1.0131\n",
            "  Batch 250/251, Loss: 0.8313\n",
            "üìà Train Loss: 0.9836, Val Loss: 1.4306, LR: 0.000026\n",
            "\n",
            "üìÖ Epoch 122/135\n",
            "  Batch 0/251, Loss: 1.0045\n",
            "  Batch 50/251, Loss: 0.8916\n",
            "  Batch 100/251, Loss: 0.7858\n",
            "  Batch 150/251, Loss: 1.0674\n",
            "  Batch 200/251, Loss: 1.0746\n",
            "  Batch 250/251, Loss: 0.8540\n",
            "üìà Train Loss: 0.9794, Val Loss: 1.4285, LR: 0.000023\n",
            "\n",
            "üìÖ Epoch 123/135\n",
            "  Batch 0/251, Loss: 1.0148\n",
            "  Batch 50/251, Loss: 1.1537\n",
            "  Batch 100/251, Loss: 0.9198\n",
            "  Batch 150/251, Loss: 1.0844\n",
            "  Batch 200/251, Loss: 1.0088\n",
            "  Batch 250/251, Loss: 1.0439\n",
            "üìà Train Loss: 0.9776, Val Loss: 1.4246, LR: 0.000019\n",
            "\n",
            "üìÖ Epoch 124/135\n",
            "  Batch 0/251, Loss: 1.0173\n",
            "  Batch 50/251, Loss: 1.1542\n",
            "  Batch 100/251, Loss: 0.9583\n",
            "  Batch 150/251, Loss: 1.1684\n",
            "  Batch 200/251, Loss: 1.0125\n",
            "  Batch 250/251, Loss: 1.0040\n",
            "üìà Train Loss: 0.9796, Val Loss: 1.4246, LR: 0.000016\n",
            "\n",
            "üìÖ Epoch 125/135\n",
            "  Batch 0/251, Loss: 0.9975\n",
            "  Batch 50/251, Loss: 1.1064\n",
            "  Batch 100/251, Loss: 0.9316\n",
            "  Batch 150/251, Loss: 0.8759\n",
            "  Batch 200/251, Loss: 1.0516\n",
            "  Batch 250/251, Loss: 0.9611\n",
            "üìà Train Loss: 0.9766, Val Loss: 1.4265, LR: 0.000013\n",
            "\n",
            "üìÖ Epoch 126/135\n",
            "  Batch 0/251, Loss: 1.0582\n",
            "  Batch 50/251, Loss: 1.2419\n",
            "  Batch 100/251, Loss: 0.8987\n",
            "  Batch 150/251, Loss: 0.8941\n",
            "  Batch 200/251, Loss: 0.8598\n",
            "  Batch 250/251, Loss: 0.9003\n",
            "üíæ Saved best model (val_loss: 1.4223)\n",
            "üìà Train Loss: 0.9757, Val Loss: 1.4223, LR: 0.000011\n",
            "\n",
            "üìÖ Epoch 127/135\n",
            "  Batch 0/251, Loss: 0.9622\n",
            "  Batch 50/251, Loss: 0.9858\n",
            "  Batch 100/251, Loss: 1.1842\n",
            "  Batch 150/251, Loss: 1.0136\n",
            "  Batch 200/251, Loss: 0.8796\n",
            "  Batch 250/251, Loss: 1.0165\n",
            "üìà Train Loss: 0.9757, Val Loss: 1.4318, LR: 0.000009\n",
            "\n",
            "üìÖ Epoch 128/135\n",
            "  Batch 0/251, Loss: 1.0333\n",
            "  Batch 50/251, Loss: 1.1464\n",
            "  Batch 100/251, Loss: 1.1295\n",
            "  Batch 150/251, Loss: 1.0491\n",
            "  Batch 200/251, Loss: 0.8124\n",
            "  Batch 250/251, Loss: 0.8947\n",
            "üíæ Saved best model (val_loss: 1.4188)\n",
            "üìà Train Loss: 0.9756, Val Loss: 1.4188, LR: 0.000007\n",
            "\n",
            "üìÖ Epoch 129/135\n",
            "  Batch 0/251, Loss: 1.0649\n",
            "  Batch 50/251, Loss: 0.8201\n",
            "  Batch 100/251, Loss: 1.0927\n",
            "  Batch 150/251, Loss: 0.9640\n",
            "  Batch 200/251, Loss: 0.8589\n",
            "  Batch 250/251, Loss: 0.9696\n",
            "üìà Train Loss: 0.9740, Val Loss: 1.4307, LR: 0.000005\n",
            "\n",
            "üìÖ Epoch 130/135\n",
            "  Batch 0/251, Loss: 0.9861\n",
            "  Batch 50/251, Loss: 1.0026\n",
            "  Batch 100/251, Loss: 1.1190\n",
            "  Batch 150/251, Loss: 0.8568\n",
            "  Batch 200/251, Loss: 0.9809\n",
            "  Batch 250/251, Loss: 0.8756\n",
            "üìà Train Loss: 0.9753, Val Loss: 1.4288, LR: 0.000003\n",
            "\n",
            "üìÖ Epoch 131/135\n",
            "  Batch 0/251, Loss: 0.7096\n",
            "  Batch 50/251, Loss: 1.2135\n",
            "  Batch 100/251, Loss: 0.8486\n",
            "  Batch 150/251, Loss: 1.1355\n",
            "  Batch 200/251, Loss: 0.8804\n",
            "  Batch 250/251, Loss: 1.0271\n",
            "üìà Train Loss: 0.9741, Val Loss: 1.4246, LR: 0.000002\n",
            "\n",
            "üìÖ Epoch 132/135\n",
            "  Batch 0/251, Loss: 0.9175\n",
            "  Batch 50/251, Loss: 1.0761\n",
            "  Batch 100/251, Loss: 0.9613\n",
            "  Batch 150/251, Loss: 0.8244\n",
            "  Batch 200/251, Loss: 0.8651\n",
            "  Batch 250/251, Loss: 1.0644\n",
            "üìà Train Loss: 0.9753, Val Loss: 1.4223, LR: 0.000001\n",
            "\n",
            "üìÖ Epoch 133/135\n",
            "  Batch 0/251, Loss: 1.0204\n",
            "  Batch 50/251, Loss: 0.9116\n",
            "  Batch 100/251, Loss: 0.9450\n",
            "  Batch 150/251, Loss: 1.1493\n",
            "  Batch 200/251, Loss: 0.9988\n",
            "  Batch 250/251, Loss: 0.9851\n",
            "üìà Train Loss: 0.9730, Val Loss: 1.4251, LR: 0.000001\n",
            "\n",
            "üìÖ Epoch 134/135\n",
            "  Batch 0/251, Loss: 0.9723\n",
            "  Batch 50/251, Loss: 0.9891\n",
            "  Batch 100/251, Loss: 0.8454\n",
            "  Batch 150/251, Loss: 0.9699\n",
            "  Batch 200/251, Loss: 1.0919\n",
            "  Batch 250/251, Loss: 0.9969\n",
            "üìà Train Loss: 0.9741, Val Loss: 1.4314, LR: 0.000000\n",
            "\n",
            "üìÖ Epoch 135/135\n",
            "  Batch 0/251, Loss: 0.9595\n",
            "  Batch 50/251, Loss: 0.8712\n",
            "  Batch 100/251, Loss: 0.9582\n",
            "  Batch 150/251, Loss: 0.8679\n",
            "  Batch 200/251, Loss: 1.0778\n",
            "  Batch 250/251, Loss: 1.1017\n",
            "üìà Train Loss: 0.9733, Val Loss: 1.4269, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Loaded best model for evaluation\n",
            "\n",
            "üîç Starting evaluation...\n",
            "üîç Evaluating model...\n",
            "üìä Phoneme Accuracy: 0.236\n",
            "\n",
            "ü§ñ Initializing full language model...\n",
            "ü§ñ Loading OPT-6.7B model (this may take a few minutes)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43f6407989484f40b0da7880268c8c62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ OPT-6.7B loaded successfully\n",
            "üîÑ Evaluating 100 samples (limited from 1376 total)\n",
            "üîÑ Converting 100 phoneme sequences to text...\n",
            "‚ö†Ô∏è  This is VERY slow with OPT-6.7B (~3-5 seconds per sequence)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting phonemes to text:   0%|          | 0/100 [2:09:04<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3645793503.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Run training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimize_for_colab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m results = main_training_pipeline(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m135\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# ‚ö†Ô∏è Use 50+ epochs! (5 epochs = 100% WER)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4170796501.py\u001b[0m in \u001b[0;36mmain_training_pipeline\u001b[0;34m(data_dir, output_dir, max_epochs, batch_size, learning_rate, use_simple_lm, use_length_grouping, bucket_boundaries, skip_full_evaluation, max_eval_samples)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0meval_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_eval_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üîÑ Evaluating {len(eval_predictions)} samples (limited from {len(val_results['predictions'])} total)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mpredicted_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphonemes_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Using full language model with OPT-6.7B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-771931587.py\u001b[0m in \u001b[0;36mphonemes_to_text\u001b[0;34m(self, phoneme_sequences)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;31m# Generate multiple candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphonemes_to_text_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphonemes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_candidates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reduced from 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;31m# Rescore with language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-771931587.py\u001b[0m in \u001b[0;36mphonemes_to_text_candidates\u001b[0;34m(self, phoneme_sequence, n_candidates)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m                     \u001b[0mcandidate_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn_candidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "data_dir = \"/content/brain2text_data\"\n",
        "\n",
        "# Run training\n",
        "optimize_for_colab()\n",
        "results = main_training_pipeline(\n",
        "    data_dir=data_dir,\n",
        "    max_epochs=135,  # ‚ö†Ô∏è Use 50+ epochs! (5 epochs = 100% WER)\n",
        "    batch_size=32,  # Reduced batch size for memory efficiency\n",
        "    use_length_grouping=True,  # Enable length grouping\n",
        "    skip_full_evaluation=False,  # Enable WER calculation\n",
        "    max_eval_samples=100  # Reasonable number for evaluation\n",
        ")\n",
        "print(f\"Training complete! WER: {results.get('wer', 'N/A')}\")\n",
        "\n",
        "# Expected results:\n",
        "# - 50 epochs: ~20-40% WER\n",
        "# - 100 epochs: ~10-15% WER\n",
        "# - 150+ epochs: ~6-8% WER (competition baseline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMmx2J46GrYA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43f6407989484f40b0da7880268c8c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f0d1fac69ca4f8aa4ee50b8c28ffe0f",
              "IPY_MODEL_eb7ffd5b29544c06ac43e8f285e03352",
              "IPY_MODEL_1361f89613e240d1b012faf48966491a"
            ],
            "layout": "IPY_MODEL_718aa29eb67c467f8f06b57d0bf9b658"
          }
        },
        "5f0d1fac69ca4f8aa4ee50b8c28ffe0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f6168f628804a4a9f3ad9af26ff981a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2e5e1435bbcf45fbac3721c228f69e2a",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "eb7ffd5b29544c06ac43e8f285e03352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b02188f1b6944d4a1f61383c7a85b77",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a56f461d5a6b49b6bb8f97e2b55901fb",
            "value": 2
          }
        },
        "1361f89613e240d1b012faf48966491a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_756198d91b14488981bfe02370e818a6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9bd15d46c72e4223874f667f3704c1d9",
            "value": "‚Äá2/2‚Äá[00:03&lt;00:00,‚Äá‚Äá1.78s/it]"
          }
        },
        "718aa29eb67c467f8f06b57d0bf9b658": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6168f628804a4a9f3ad9af26ff981a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e5e1435bbcf45fbac3721c228f69e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b02188f1b6944d4a1f61383c7a85b77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a56f461d5a6b49b6bb8f97e2b55901fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "756198d91b14488981bfe02370e818a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bd15d46c72e4223874f667f3704c1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}